{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import egfr_binder_rd2 as egfr\n",
    "from egfr_binder_rd2.expression_dataset import get_data, get_by_seq_data, create_data_splits_grouped\n",
    "from egfr_binder_rd2.solubility import calculate_solubility\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:26:51,340 - INFO - HTTP Request: GET https://polarishub.io/api/v1/dataset/adaptyv-bio/egfr-binders-v0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:26:51,959 - INFO - HTTP Request: GET https://polarishub.io/storage/dataset/adaptyv-bio/egfr-binders-v0/table.parquet \"HTTP/1.1 307 Temporary Redirect\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:26:52,229 - INFO - HTTP Request: GET https://874f02b9d981bd6c279e979c0d91c4b4.r2.cloudflarestorage.com/polaris/dataset/adaptyv-bio/egfr-binders-v0/table.parquet?X-Amz-Expires=3600&X-Amz-Date=20241104T162651Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=810f02be0d7621779492bf8c1c1de2ce%2F20241104%2Fauto%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=2f96684a401ac084abdf3a847fb88eecc2ba7b878e87c784ee143191067d1b5b \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-04 08:26:52.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.8.7.dev1+g23fd61e.d20240926) is different from the currently installed version of Polaris (0.8.6).\u001b[0m\n",
      "\u001b[32m2024-11-04 08:26:52.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris.mixins._checksum\u001b[0m:\u001b[36mverify_checksum\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mTo verify the checksum, we need to recompute it. This can be slow for large datasets.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SUCCESS: \u001b[1mFetched artifact.\u001b[0m\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/yaspin/core.py:239: UserWarning: color, on_color and attrs are not supported when running in jupyter\n",
      "  self._color = self._set_color(value) if value else value\n"
     ]
    }
   ],
   "source": [
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Fetching artifact..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:31:34,292 - INFO - HTTP Request: GET https://polarishub.io/api/v1/dataset/adaptyv-bio/egfr-binders-v0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:31:34,851 - INFO - HTTP Request: GET https://polarishub.io/storage/dataset/adaptyv-bio/egfr-binders-v0/table.parquet \"HTTP/1.1 307 Temporary Redirect\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:31:35,183 - INFO - HTTP Request: GET https://874f02b9d981bd6c279e979c0d91c4b4.r2.cloudflarestorage.com/polaris/dataset/adaptyv-bio/egfr-binders-v0/table.parquet?X-Amz-Expires=3600&X-Amz-Date=20241104T163134Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=810f02be0d7621779492bf8c1c1de2ce%2F20241104%2Fauto%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=82e94310f1fa95d45bf8cc8e5143e8167514704d853c4bcb477ff14e8a773047 \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2024-11-04 08:31:35.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.8.7.dev1+g23fd61e.d20240926) is different from the currently installed version of Polaris (0.8.6).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-04 08:31:35.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris.mixins._checksum\u001b[0m:\u001b[36mverify_checksum\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mTo verify the checksum, we need to recompute it. This can be slow for large datasets.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SUCCESS: \u001b[1mFetched artifact.\u001b[0m\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/yaspin/core.py:239: UserWarning: color, on_color and attrs are not supported when running in jupyter\n",
      "  self._color = self._set_color(value) if value else value\n"
     ]
    }
   ],
   "source": [
    "df = get_by_seq_data()\n",
    "split_df = create_data_splits_grouped(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>sequence</th>\n",
       "      <th>length</th>\n",
       "      <th>encoded_expression</th>\n",
       "      <th>perc_charged</th>\n",
       "      <th>perc_hydrophobic</th>\n",
       "      <th>p_soluble</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Razora712</td>\n",
       "      <td>EALEEALKALKAEHAKKRKAIYDELLESHSNIADKVEKGEINKEEA...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.998085</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Razora712</td>\n",
       "      <td>EELKKALQALKKEYRDKQWAVVQEMLKQHAEIAKKKEAGEINEKEA...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Razora712</td>\n",
       "      <td>KELEEARKKLKEEIIKEKKAIVDQELKNHAEIADLVEAGKINEKEA...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.999342</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Razora712</td>\n",
       "      <td>RVKELEEEAKRKADEAEELKKRIDALQAKFNELLAAAKASSDPRKS...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.989838</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adrian.tripp</td>\n",
       "      <td>MAKLIIANSEEALKEYLEKLGEEAKDYEKVVVPLGDGSVVQSAQNA...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.801143</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>ATAAKKAQLEAEAAKKEAEAAEAKAKAKQVEDDAAKKLAELDVAAG...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.997806</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>DEVEKLREEAIKEIEEARRLIEEARERVGDACGPYADAAASSYEEA...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.994729</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>DLELAERLAAQLPDADEALEALRTAVTAGNLVDGAAQVLALGAAAA...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.864252</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>DQKVTELNKAALQYEAEAAEYRTKAKTYDELSKGSGGGLYSKKAAD...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>GTAAQKAQLLQQAADNEAQAEAAAAEAKATEDKAAEKAAELDVLAA...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.992001</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               username                                           sequence  \\\n",
       "0             Razora712  EALEEALKALKAEHAKKRKAIYDELLESHSNIADKVEKGEINKEEA...   \n",
       "1             Razora712  EELKKALQALKKEYRDKQWAVVQEMLKQHAEIAKKKEAGEINEKEA...   \n",
       "2             Razora712  KELEEARKKLKEEIIKEKKAIVDQELKNHAEIADLVEAGKINEKEA...   \n",
       "3             Razora712  RVKELEEEAKRKADEAEELKKRIDALQAKFNELLAAAKASSDPRKS...   \n",
       "4          adrian.tripp  MAKLIIANSEEALKEYLEKLGEEAKDYEKVVVPLGDGSVVQSAQNA...   \n",
       "..                  ...                                                ...   \n",
       "187  vratinsrivastava10  ATAAKKAQLEAEAAKKEAEAAEAKAKAKQVEDDAAKKLAELDVAAG...   \n",
       "188  vratinsrivastava10  DEVEKLREEAIKEIEEARRLIEEARERVGDACGPYADAAASSYEEA...   \n",
       "189  vratinsrivastava10  DLELAERLAAQLPDADEALEALRTAVTAGNLVDGAAQVLALGAAAA...   \n",
       "190  vratinsrivastava10  DQKVTELNKAALQYEAEAAEYRTKAKTYDELSKGSGGGLYSKKAAD...   \n",
       "191  vratinsrivastava10  GTAAQKAQLLQQAADNEAQAEAAAAEAKATEDKAAEKAAELDVLAA...   \n",
       "\n",
       "     length  encoded_expression  perc_charged  perc_hydrophobic  p_soluble  \\\n",
       "0      75.0                 2.0      0.546667          0.213333   0.998085   \n",
       "1      75.0                 3.0      0.520000          0.226667   0.997512   \n",
       "2      75.0                 3.0      0.586667          0.186667   0.999342   \n",
       "3      87.0                 3.0      0.459770          0.218391   0.989838   \n",
       "4     150.0                 3.0      0.266667          0.393333   0.801143   \n",
       "..      ...                 ...           ...               ...        ...   \n",
       "187   100.0                 2.0      0.350000          0.110000   0.997806   \n",
       "188   100.0                 3.0      0.470000          0.180000   0.994729   \n",
       "189    70.0                 2.5      0.214286          0.271429   0.864252   \n",
       "190    70.0                 3.0      0.385714          0.200000   0.979146   \n",
       "191   100.0                 2.5      0.300000          0.130000   0.992001   \n",
       "\n",
       "     stage  \n",
       "0    train  \n",
       "1    train  \n",
       "2    train  \n",
       "3    train  \n",
       "4    train  \n",
       "..     ...  \n",
       "187   test  \n",
       "188   test  \n",
       "189   test  \n",
       "190   test  \n",
       "191   test  \n",
       "\n",
       "[201 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>encoded_expression</th>\n",
       "      <th>p_charged</th>\n",
       "      <th>p_hydrophobic</th>\n",
       "      <th>p_soluble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVEKILKVGEEALKDPSQAENAEAVFKLAKGVAEDAIKSTKARIKKAK</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351648</td>\n",
       "      <td>0.197802</td>\n",
       "      <td>0.994190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AALKAKVEALVDKAIAAAKAGDFDAALKYAEDALLAAEAAGDGELAEEAVKRIIEAVPSLPQYYKDLLRAFAERVKSKAA</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.956122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADPEKAREYVKKAREAIKEAEKALKDGTEEAIKKAQEKALEMMELLAEARKEGFPDTLIAMLAYAALAAGEYATAATLKNKGTDPEAAARHERLGKLAAERALGLGELVL</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.980028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AEEEDKKKLEEFKKFAEEKVKEAKKLLEEAKKKVEEAKKKGDPEELRKAAEFARKAAEEAEELLWEVLKKAHEVASSSSPKYAEEAKKEAAKAAEEIGKIREELWDLSNEAAAAAEEVEAA</th>\n",
       "      <td>121.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.998922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AELQQKIKDATAKAIAAAKAGDSDGVVAASSDIVTYSIELGDYAAGYNALKEVMEAAKDNDPLALSIIRQMGKSLRLLAN</th>\n",
       "      <td>80.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.859475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLSINKDNSKSQVFFKMNSLQSNDTAIYYCARALVHHSYEFAYWGQGTLVTVSAASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLNVRAYICNVNHKPSNTKVDKKVQAKSC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.356858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WNPRAEAQAIFDCALNDCY</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.251169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WNPRAEAQARFDCALNDCW</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.357872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WVQLQESGGGLVQPGGSLRLSCAASGRTFSSYAMGWFRQAPGKQREFVAAIRWSGGYTYYTDSVKGRFTISRDNAKTTVYLQMNSLKPEDTAVYYCAATYLSSDYSRYALPQRPLDYDYWGQGTQVTVSSLE</th>\n",
       "      <td>132.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.174242</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.218824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YTKEEVIEALKRAIEEAEKALEELPKNPTLGAALICDAALIAIDAAYLVEEALGEEFKELAEKLREAALEALEAVKAGDLEKAKEYLEKAKEIAKEILKKI</th>\n",
       "      <td>101.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.405941</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.985153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    length  \\\n",
       "sequence                                                     \n",
       "AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVEK...    91.0   \n",
       "AALKAKVEALVDKAIAAAKAGDFDAALKYAEDALLAAEAAGDGELAE...    80.0   \n",
       "ADPEKAREYVKKAREAIKEAEKALKDGTEEAIKKAQEKALEMMELLA...   110.0   \n",
       "AEEEDKKKLEEFKKFAEEKVKEAKKLLEEAKKKVEEAKKKGDPEELR...   121.0   \n",
       "AELQQKIKDATAKAIAAAKAGDSDGVVAASSDIVTYSIELGDYAAGY...    80.0   \n",
       "...                                                    ...   \n",
       "TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLSI...     NaN   \n",
       "WNPRAEAQAIFDCALNDCY                                   19.0   \n",
       "WNPRAEAQARFDCALNDCW                                   19.0   \n",
       "WVQLQESGGGLVQPGGSLRLSCAASGRTFSSYAMGWFRQAPGKQREF...   132.0   \n",
       "YTKEEVIEALKRAIEEAEKALEELPKNPTLGAALICDAALIAIDAAY...   101.0   \n",
       "\n",
       "                                                    encoded_expression  \\\n",
       "sequence                                                                 \n",
       "AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVEK...            0.000000   \n",
       "AALKAKVEALVDKAIAAAKAGDFDAALKYAEDALLAAEAAGDGELAE...            2.000000   \n",
       "ADPEKAREYVKKAREAIKEAEKALKDGTEEAIKKAQEKALEMMELLA...            0.000000   \n",
       "AEEEDKKKLEEFKKFAEEKVKEAKKLLEEAKKKVEEAKKKGDPEELR...            2.666667   \n",
       "AELQQKIKDATAKAIAAAKAGDSDGVVAASSDIVTYSIELGDYAAGY...            3.000000   \n",
       "...                                                                ...   \n",
       "TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLSI...            1.666667   \n",
       "WNPRAEAQAIFDCALNDCY                                           3.000000   \n",
       "WNPRAEAQARFDCALNDCW                                           3.000000   \n",
       "WVQLQESGGGLVQPGGSLRLSCAASGRTFSSYAMGWFRQAPGKQREF...            2.000000   \n",
       "YTKEEVIEALKRAIEEAEKALEELPKNPTLGAALICDAALIAIDAAY...            3.000000   \n",
       "\n",
       "                                                    p_charged  p_hydrophobic  \\\n",
       "sequence                                                                       \n",
       "AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVEK...   0.351648       0.197802   \n",
       "AALKAKVEALVDKAIAAAKAGDFDAALKYAEDALLAAEAAGDGELAE...   0.325000       0.275000   \n",
       "ADPEKAREYVKKAREAIKEAEKALKDGTEEAIKKAQEKALEMMELLA...   0.372727       0.236364   \n",
       "AEEEDKKKLEEFKKFAEEKVKEAKKLLEEAKKKVEEAKKKGDPEELR...   0.520661       0.181818   \n",
       "AELQQKIKDATAKAIAAAKAGDSDGVVAASSDIVTYSIELGDYAAGY...   0.250000       0.287500   \n",
       "...                                                       ...            ...   \n",
       "TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLSI...   0.155000       0.315000   \n",
       "WNPRAEAQAIFDCALNDCY                                  0.210526       0.263158   \n",
       "WNPRAEAQARFDCALNDCW                                  0.263158       0.210526   \n",
       "WVQLQESGGGLVQPGGSLRLSCAASGRTFSSYAMGWFRQAPGKQREF...   0.174242       0.318182   \n",
       "YTKEEVIEALKRAIEEAEKALEELPKNPTLGAALICDAALIAIDAAY...   0.405941       0.297030   \n",
       "\n",
       "                                                    p_soluble  \n",
       "sequence                                                       \n",
       "AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVEK...   0.994190  \n",
       "AALKAKVEALVDKAIAAAKAGDFDAALKYAEDALLAAEAAGDGELAE...   0.956122  \n",
       "ADPEKAREYVKKAREAIKEAEKALKDGTEEAIKKAQEKALEMMELLA...   0.980028  \n",
       "AEEEDKKKLEEFKKFAEEKVKEAKKLLEEAKKKVEEAKKKGDPEELR...   0.998922  \n",
       "AELQQKIKDATAKAIAAAKAGDSDGVVAASSDIVTYSIELGDYAAGY...   0.859475  \n",
       "...                                                       ...  \n",
       "TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLSI...   0.356858  \n",
       "WNPRAEAQAIFDCALNDCY                                  0.251169  \n",
       "WNPRAEAQARFDCALNDCW                                  0.357872  \n",
       "WVQLQESGGGLVQPGGSLRLSCAASGRTFSSYAMGWFRQAPGKQREF...   0.218824  \n",
       "YTKEEVIEALKRAIEEAEKALEELPKNPTLGAALICDAALIAIDAAY...   0.985153  \n",
       "\n",
       "[213 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>KD</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dna</th>\n",
       "      <th>plddt</th>\n",
       "      <th>pae_interaction</th>\n",
       "      <th>similarity_check</th>\n",
       "      <th>model_names</th>\n",
       "      <th>...</th>\n",
       "      <th>kd</th>\n",
       "      <th>kon</th>\n",
       "      <th>koff</th>\n",
       "      <th>binding</th>\n",
       "      <th>confidence</th>\n",
       "      <th>expression</th>\n",
       "      <th>nc_adjusted_expression</th>\n",
       "      <th>length</th>\n",
       "      <th>binding_strength</th>\n",
       "      <th>encoded_expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>joaosartori2-design8</td>\n",
       "      <td>joaosartori2</td>\n",
       "      <td>design8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QVKLEESGGGSVQTGGSLRLTCAASGVNINSYYIYWFRQAPGKERE...</td>\n",
       "      <td>ATGCAGGTGAAACTGGAAGAAAGCGGCGGCGGCTCTGTTCAAACTG...</td>\n",
       "      <td>77.554677</td>\n",
       "      <td>27.569762</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>[\"ESM2\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>cchallacombe-thermo1</td>\n",
       "      <td>cchallacombe</td>\n",
       "      <td>thermo1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVQLVESGGGLVQAGGSLRLSCAASGRTFSSYIMGWFRQAPGKERE...</td>\n",
       "      <td>ATGGAAGTGCAGCTGGTGGAAAGCGGCGGCGGCCTGGTTCAAGCAG...</td>\n",
       "      <td>75.630630</td>\n",
       "      <td>28.163272</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>evarist.planet-FM_75_1_76</td>\n",
       "      <td>evarist.planet</td>\n",
       "      <td>FM_75_1_76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PELPPEVRAALEALLGEAPIQITLKQVGGDLVATAVSFETGKFAIL...</td>\n",
       "      <td>ATGCCGGAACTGCCGCCGGAAGTGCGCGCGGCGCTGGAAGCATTAT...</td>\n",
       "      <td>50.365333</td>\n",
       "      <td>21.068868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ccalia-conf94_139_2</td>\n",
       "      <td>ccalia</td>\n",
       "      <td>conf94_139_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVE...</td>\n",
       "      <td>ATGGCGGCGCTGGAAGCGGCGAAAAAAGCCCTGGAGGCGGCGAAGA...</td>\n",
       "      <td>86.619011</td>\n",
       "      <td>16.731577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gitter-yolo5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTTSSIRRQMKNIVNNYSEAEIKVREATSNDPWGPSSSLMTEIADL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>salireza111-mini_1_0_</td>\n",
       "      <td>salireza111</td>\n",
       "      <td>mini_1_0_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEEADKKAEEARKEFDKQRK</td>\n",
       "      <td>ATGAGCGAAGAAGCGGATAAAAAAGCGGAGGAGGCCCGCAAAGAAT...</td>\n",
       "      <td>68.288500</td>\n",
       "      <td>15.236520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>alex.naka-af805e</td>\n",
       "      <td>alex.naka</td>\n",
       "      <td>af805e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PSYSACPVRYDGFCGNGGVCKHIESLDSYTCQCVIGYSGHREQTYD...</td>\n",
       "      <td>ATGCCGAGCTATAGCGCGTGCCCGGTGCGCTATGATGGCTTTTGCG...</td>\n",
       "      <td>90.880400</td>\n",
       "      <td>7.919135</td>\n",
       "      <td>0.719100</td>\n",
       "      <td>[\"Custom (Active Learning)\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>alecl-Sequence10</td>\n",
       "      <td>alecl</td>\n",
       "      <td>Sequence10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EINEECPWSFSGYCQNEGVCLFLEKTNRYACQCQNGYIGERCEWRD...</td>\n",
       "      <td>ATGGAAATTAACGAAGAATGCCCGTGGAGCTTTAGCGGCTATTGCC...</td>\n",
       "      <td>84.454340</td>\n",
       "      <td>9.333907</td>\n",
       "      <td>0.527744</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>akshayc-9_run_3_1002_dldesign_0_cycle1_af2pred</td>\n",
       "      <td>akshaychenna</td>\n",
       "      <td>9_run_3_1002_dldesign_0_cycle1_af2pred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GISESLAMLEFLKKLAEALAPLTKIEEEAEKELKEKIKELVPEGSE...</td>\n",
       "      <td>ATGGGCATTAGCGAAAGCCTGGCGATGCTGGAATTTCTGAAAAAAC...</td>\n",
       "      <td>90.860385</td>\n",
       "      <td>15.344847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>vratinsrivastava10-sequence_9</td>\n",
       "      <td>vratinsrivastava10</td>\n",
       "      <td>sequence_9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATAAKKAQLEAEAAKKEAEAAEAKAKAKQVEDDAAKKLAELDVAAG...</td>\n",
       "      <td>ATGGCGACCGCGGCGAAAAAAGCGCAGCTGGAAGCGGAAGCGGCTA...</td>\n",
       "      <td>45.386000</td>\n",
       "      <td>23.642914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>theraven-sequence45</td>\n",
       "      <td>theraven</td>\n",
       "      <td>sequence45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEETKAKAEELKTKAAEAKYKHAELLAKGDELYKEAPKSKEAADKA...</td>\n",
       "      <td>ATGAGCGAAGAAACCAAAGCGAAAGCGGAAGAACTGAAGACGAAGG...</td>\n",
       "      <td>80.755775</td>\n",
       "      <td>15.492161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>nickboyd-Domain1_Seq3</td>\n",
       "      <td>nickboyd</td>\n",
       "      <td>Domain1_Seq3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIYEAIADILMEKYNVSREVALKAAKEAGGNYEKAEELVKKSL</td>\n",
       "      <td>ATGGATATTTACGAAGCGATTGCGGATATCCTGATGGAAAAATATA...</td>\n",
       "      <td>88.527442</td>\n",
       "      <td>13.452572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>jvogt4-hotspots_only_484_01</td>\n",
       "      <td>jvogt4</td>\n",
       "      <td>hotspots_only_484_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STPEAEAFEKKLAALEEEKAEDLIALINAQAEAMKAAKDGDEAAKL...</td>\n",
       "      <td>ATGAGCACCCCGGAAGCGGAAGCGTTTGAAAAGAAACTGGCGGCGC...</td>\n",
       "      <td>87.226056</td>\n",
       "      <td>18.694262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>theraven-sequence47</td>\n",
       "      <td>theraven</td>\n",
       "      <td>sequence47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEETKAKAEELQTKALEAKYKAAELLAKGDELYKEAPKSKEAADKA...</td>\n",
       "      <td>ATGAGCGAAGAAACCAAAGCGAAAGCGGAAGAACTGCAGACGAAGG...</td>\n",
       "      <td>77.381690</td>\n",
       "      <td>15.909546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>joaosartori2-design1</td>\n",
       "      <td>joaosartori2</td>\n",
       "      <td>design1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QVKLEESGGGSVQTGGSLRLTCAASGVNINSYYIYWFRQAPGKERE...</td>\n",
       "      <td>ATGCAGGTGAAACTGGAAGAAAGCGGCGGCGGCAGCGTTCAAACTG...</td>\n",
       "      <td>77.637823</td>\n",
       "      <td>27.020995</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>[\"ESM2\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>x.rustamov-m_15_28</td>\n",
       "      <td>x.rustamov</td>\n",
       "      <td>m_15_28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKDKLNELAKQAIAYAAAIFGDHPLLSEFTSQVNSIAEDLSKENVS...</td>\n",
       "      <td>ATGAAAGATAAACTGAACGAACTGGCGAAACAGGCGATTGCGTATG...</td>\n",
       "      <td>87.471000</td>\n",
       "      <td>15.706559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"AF2 Backprop\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>x.rustamov-m_18_41</td>\n",
       "      <td>x.rustamov</td>\n",
       "      <td>m_18_41</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>SAGQAQIEEVKARADKAKTLEELKELRKEAYEKNWKAYMAVVDETE...</td>\n",
       "      <td>ATGAGCGCGGGCCAGGCGCAGATTGAAGAAGTGAAAGCGCGCGCAG...</td>\n",
       "      <td>89.580600</td>\n",
       "      <td>14.921833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"AF2 Backprop\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>svs25-seq3</td>\n",
       "      <td>svs25</td>\n",
       "      <td>seq3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDLPGCPPELAGYCPCGGKCVYNAATNSVSCECSPGCSGPPCTLCD...</td>\n",
       "      <td>ATGCCGGATCTGCCGGGCTGCCCGCCGGAATTAGCGGGTTATTGTC...</td>\n",
       "      <td>41.997547</td>\n",
       "      <td>20.797714</td>\n",
       "      <td>0.360220</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>evarist.planet-FM_75_7_16</td>\n",
       "      <td>evarist.planet</td>\n",
       "      <td>FM_75_7_16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LTLPPSAQAQIEQLKQNPNYELTLFLSGGRPVVEVYNKETGAVTYS...</td>\n",
       "      <td>ATGCTGACCCTGCCGCCGAGCGCGCAGGCGCAGATCGAGCAGTTAA...</td>\n",
       "      <td>26.721833</td>\n",
       "      <td>23.327960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>alecl-Sequence7</td>\n",
       "      <td>alecl</td>\n",
       "      <td>Sequence7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HHHHHCPASYDGFCHNDGTCLFIAATNRYACRCTEGYIGKRCEFKD...</td>\n",
       "      <td>ATGCATCATCATCATCATTGCCCGGCGAGCTATGATGGCTTTTGCC...</td>\n",
       "      <td>84.407925</td>\n",
       "      <td>9.430105</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>alecl-Sequence5</td>\n",
       "      <td>alecl</td>\n",
       "      <td>Sequence5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HTERQCPSSYDGYCKNDGVCQFLEALSEYACTCTTGYIGERCEFAD...</td>\n",
       "      <td>ATGCATACCGAACGCCAGTGCCCGAGCAGCTATGATGGCTATTGCA...</td>\n",
       "      <td>86.462642</td>\n",
       "      <td>9.042515</td>\n",
       "      <td>0.565936</td>\n",
       "      <td>[\"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>carlos.bueno-WWB53</td>\n",
       "      <td>carlos.bueno</td>\n",
       "      <td>WWB53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MYEVSAQQKQQKTSRQSNTHHTVHIYNKIDEIVIFVVAEKKTQITV...</td>\n",
       "      <td>ATGTATGAAGTGAGCGCGCAGCAGAAACAACAAAAGACCAGCCGCC...</td>\n",
       "      <td>30.306500</td>\n",
       "      <td>26.552847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>none</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>eugene.valkov-rfdiff_design_88_34_dldesign_1_a...</td>\n",
       "      <td>eugene.valkov</td>\n",
       "      <td>rfdiff_design_88_34_dldesign_1_af2pred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KLEEIKKKQELANKLAAEDEIMWDIQVLLLELEAEGVSEEEKDKIL...</td>\n",
       "      <td>ATGAAACTGGAAGAAATTAAAAAGAAACAGGAACTGGCGAACAAAC...</td>\n",
       "      <td>79.703494</td>\n",
       "      <td>18.945050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>nasr.kaveh-ZistRayaneshDesign-02</td>\n",
       "      <td>nasr.kaveh</td>\n",
       "      <td>ZistRayaneshDesign-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPAREEIERHTALALEACEAGDADGALNHALKADLLAKAAGDYALG...</td>\n",
       "      <td>ATGGGCCCGGCGCGCGAAGAAATTGAACGCCATACCGCGTTAGCAT...</td>\n",
       "      <td>79.757500</td>\n",
       "      <td>13.819649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>alex.naka-aa2c76</td>\n",
       "      <td>alex.naka</td>\n",
       "      <td>aa2c76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PSYSACPSSYDGYCGNGGVCKHIESLDSYTCQCVIGCSGDRDQTAD...</td>\n",
       "      <td>ATGCCGAGCTATAGCGCGTGCCCGAGCAGCTATGATGGCTATTGCG...</td>\n",
       "      <td>90.827000</td>\n",
       "      <td>8.043052</td>\n",
       "      <td>0.779520</td>\n",
       "      <td>[\"Custom (Active Learning)\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>aqamar-seq7</td>\n",
       "      <td>aqamar</td>\n",
       "      <td>seq7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEARKRLAASNAKNAALHETFLAEAEAEAAARAARSEAARAAAAEA...</td>\n",
       "      <td>ATGGATGAAGCGCGCAAACGCCTGGCGGCGAGCAACGCGAAAAACG...</td>\n",
       "      <td>27.680588</td>\n",
       "      <td>22.689358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>akshayc-3_run_3_168_dldesign_0_cycle1_af2pred</td>\n",
       "      <td>akshaychenna</td>\n",
       "      <td>3_run_3_168_dldesign_0_cycle1_af2pred</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DVERYKETLEESKKELDKEKKKAEAELKKAKEDAAKASPEEAAKYK...</td>\n",
       "      <td>ATGGATGTGGAACGCTATAAGGAGACCCTGGAAGAAAGCAAAAAAG...</td>\n",
       "      <td>83.569875</td>\n",
       "      <td>15.678809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>x.rustamov-s_15_28</td>\n",
       "      <td>x.rustamov</td>\n",
       "      <td>s_15_28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKEKLNELADEAISFAKSIFGDHPSLATFTSFANSVADDLSKEDIS...</td>\n",
       "      <td>ATGAAAGAAAAACTGAACGAACTGGCGGATGAAGCGATTAGCTTTG...</td>\n",
       "      <td>90.417200</td>\n",
       "      <td>16.367008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"AF2 Backprop\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gitter-yolo2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ryanba-seq45</td>\n",
       "      <td>ryanba</td>\n",
       "      <td>seq45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EKESQEIINLISSLSLEFLIEIDKLLPEISQEEKDELATELIRELR...</td>\n",
       "      <td>ATGGAAAAAGAAAGCCAGGAAATTATTAACCTGATCAGCAGCCTGA...</td>\n",
       "      <td>84.002000</td>\n",
       "      <td>15.460188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name            username  \\\n",
       "262                               joaosartori2-design8        joaosartori2   \n",
       "180                               cchallacombe-thermo1        cchallacombe   \n",
       "227                          evarist.planet-FM_75_1_76      evarist.planet   \n",
       "171                                ccalia-conf94_139_2              ccalia   \n",
       "20                                        gitter-yolo5                 NaN   \n",
       "362                              salireza111-mini_1_0_         salireza111   \n",
       "85                                    alex.naka-af805e           alex.naka   \n",
       "46                                    alecl-Sequence10               alecl   \n",
       "38      akshayc-9_run_3_1002_dldesign_0_cycle1_af2pred        akshaychenna   \n",
       "441                      vratinsrivastava10-sequence_9  vratinsrivastava10   \n",
       "400                                theraven-sequence45            theraven   \n",
       "334                              nickboyd-Domain1_Seq3            nickboyd   \n",
       "268                        jvogt4-hotspots_only_484_01              jvogt4   \n",
       "403                                theraven-sequence47            theraven   \n",
       "255                               joaosartori2-design1        joaosartori2   \n",
       "446                                 x.rustamov-m_15_28          x.rustamov   \n",
       "447                                 x.rustamov-m_18_41          x.rustamov   \n",
       "378                                         svs25-seq3               svs25   \n",
       "235                          evarist.planet-FM_75_7_16      evarist.planet   \n",
       "62                                     alecl-Sequence7               alecl   \n",
       "57                                     alecl-Sequence5               alecl   \n",
       "154                                 carlos.bueno-WWB53        carlos.bueno   \n",
       "224  eugene.valkov-rfdiff_design_88_34_dldesign_1_a...       eugene.valkov   \n",
       "318                   nasr.kaveh-ZistRayaneshDesign-02          nasr.kaveh   \n",
       "81                                    alex.naka-aa2c76           alex.naka   \n",
       "114                                        aqamar-seq7              aqamar   \n",
       "31       akshayc-3_run_3_168_dldesign_0_cycle1_af2pred        akshaychenna   \n",
       "453                                 x.rustamov-s_15_28          x.rustamov   \n",
       "9                                         gitter-yolo2                 NaN   \n",
       "360                                       ryanba-seq45              ryanba   \n",
       "\n",
       "                              sequence_name        KD  \\\n",
       "262                                 design8       NaN   \n",
       "180                                 thermo1       NaN   \n",
       "227                              FM_75_1_76       NaN   \n",
       "171                            conf94_139_2       NaN   \n",
       "20                                      NaN       NaN   \n",
       "362                               mini_1_0_       NaN   \n",
       "85                                   af805e       NaN   \n",
       "46                               Sequence10       NaN   \n",
       "38   9_run_3_1002_dldesign_0_cycle1_af2pred       NaN   \n",
       "441                              sequence_9       NaN   \n",
       "400                              sequence45       NaN   \n",
       "334                            Domain1_Seq3       NaN   \n",
       "268                    hotspots_only_484_01       NaN   \n",
       "403                              sequence47       NaN   \n",
       "255                                 design1       NaN   \n",
       "446                                 m_15_28       NaN   \n",
       "447                                 m_18_41  0.000005   \n",
       "378                                    seq3       NaN   \n",
       "235                              FM_75_7_16       NaN   \n",
       "62                                Sequence7       NaN   \n",
       "57                                Sequence5       NaN   \n",
       "154                                   WWB53       NaN   \n",
       "224  rfdiff_design_88_34_dldesign_1_af2pred       NaN   \n",
       "318                   ZistRayaneshDesign-02       NaN   \n",
       "81                                   aa2c76       NaN   \n",
       "114                                    seq7       NaN   \n",
       "31    3_run_3_168_dldesign_0_cycle1_af2pred       NaN   \n",
       "453                                 s_15_28       NaN   \n",
       "9                                       NaN       NaN   \n",
       "360                                   seq45       NaN   \n",
       "\n",
       "                                              sequence  \\\n",
       "262  QVKLEESGGGSVQTGGSLRLTCAASGVNINSYYIYWFRQAPGKERE...   \n",
       "180  EVQLVESGGGLVQAGGSLRLSCAASGRTFSSYIMGWFRQAPGKERE...   \n",
       "227  PELPPEVRAALEALLGEAPIQITLKQVGGDLVATAVSFETGKFAIL...   \n",
       "171  AALEAAKKALEAAKKALAELKAAAKEAEKVNPGAGALANTMAEAVE...   \n",
       "20   MTTSSIRRQMKNIVNNYSEAEIKVREATSNDPWGPSSSLMTEIADL...   \n",
       "362                               SEEADKKAEEARKEFDKQRK   \n",
       "85   PSYSACPVRYDGFCGNGGVCKHIESLDSYTCQCVIGYSGHREQTYD...   \n",
       "46   EINEECPWSFSGYCQNEGVCLFLEKTNRYACQCQNGYIGERCEWRD...   \n",
       "38   GISESLAMLEFLKKLAEALAPLTKIEEEAEKELKEKIKELVPEGSE...   \n",
       "441  ATAAKKAQLEAEAAKKEAEAAEAKAKAKQVEDDAAKKLAELDVAAG...   \n",
       "400  SEETKAKAEELKTKAAEAKYKHAELLAKGDELYKEAPKSKEAADKA...   \n",
       "334        DIYEAIADILMEKYNVSREVALKAAKEAGGNYEKAEELVKKSL   \n",
       "268  STPEAEAFEKKLAALEEEKAEDLIALINAQAEAMKAAKDGDEAAKL...   \n",
       "403  SEETKAKAEELQTKALEAKYKAAELLAKGDELYKEAPKSKEAADKA...   \n",
       "255  QVKLEESGGGSVQTGGSLRLTCAASGVNINSYYIYWFRQAPGKERE...   \n",
       "446  MKDKLNELAKQAIAYAAAIFGDHPLLSEFTSQVNSIAEDLSKENVS...   \n",
       "447  SAGQAQIEEVKARADKAKTLEELKELRKEAYEKNWKAYMAVVDETE...   \n",
       "378  PDLPGCPPELAGYCPCGGKCVYNAATNSVSCECSPGCSGPPCTLCD...   \n",
       "235  LTLPPSAQAQIEQLKQNPNYELTLFLSGGRPVVEVYNKETGAVTYS...   \n",
       "62   HHHHHCPASYDGFCHNDGTCLFIAATNRYACRCTEGYIGKRCEFKD...   \n",
       "57   HTERQCPSSYDGYCKNDGVCQFLEALSEYACTCTTGYIGERCEFAD...   \n",
       "154  MYEVSAQQKQQKTSRQSNTHHTVHIYNKIDEIVIFVVAEKKTQITV...   \n",
       "224  KLEEIKKKQELANKLAAEDEIMWDIQVLLLELEAEGVSEEEKDKIL...   \n",
       "318  GPAREEIERHTALALEACEAGDADGALNHALKADLLAKAAGDYALG...   \n",
       "81   PSYSACPSSYDGYCGNGGVCKHIESLDSYTCQCVIGCSGDRDQTAD...   \n",
       "114  DEARKRLAASNAKNAALHETFLAEAEAEAAARAARSEAARAAAAEA...   \n",
       "31   DVERYKETLEESKKELDKEKKKAEAELKKAKEDAAKASPEEAAKYK...   \n",
       "453  MKEKLNELADEAISFAKSIFGDHPSLATFTSFANSVADDLSKEDIS...   \n",
       "9    TVSGFDLTDYGVHWVRQSPGKGLEWLGVIWSGGNTDYNTPFTSRLS...   \n",
       "360  EKESQEIINLISSLSLEFLIEIDKLLPEISQEEKDELATELIRELR...   \n",
       "\n",
       "                                                   dna      plddt  \\\n",
       "262  ATGCAGGTGAAACTGGAAGAAAGCGGCGGCGGCTCTGTTCAAACTG...  77.554677   \n",
       "180  ATGGAAGTGCAGCTGGTGGAAAGCGGCGGCGGCCTGGTTCAAGCAG...  75.630630   \n",
       "227  ATGCCGGAACTGCCGCCGGAAGTGCGCGCGGCGCTGGAAGCATTAT...  50.365333   \n",
       "171  ATGGCGGCGCTGGAAGCGGCGAAAAAAGCCCTGGAGGCGGCGAAGA...  86.619011   \n",
       "20                                                 NaN        NaN   \n",
       "362  ATGAGCGAAGAAGCGGATAAAAAAGCGGAGGAGGCCCGCAAAGAAT...  68.288500   \n",
       "85   ATGCCGAGCTATAGCGCGTGCCCGGTGCGCTATGATGGCTTTTGCG...  90.880400   \n",
       "46   ATGGAAATTAACGAAGAATGCCCGTGGAGCTTTAGCGGCTATTGCC...  84.454340   \n",
       "38   ATGGGCATTAGCGAAAGCCTGGCGATGCTGGAATTTCTGAAAAAAC...  90.860385   \n",
       "441  ATGGCGACCGCGGCGAAAAAAGCGCAGCTGGAAGCGGAAGCGGCTA...  45.386000   \n",
       "400  ATGAGCGAAGAAACCAAAGCGAAAGCGGAAGAACTGAAGACGAAGG...  80.755775   \n",
       "334  ATGGATATTTACGAAGCGATTGCGGATATCCTGATGGAAAAATATA...  88.527442   \n",
       "268  ATGAGCACCCCGGAAGCGGAAGCGTTTGAAAAGAAACTGGCGGCGC...  87.226056   \n",
       "403  ATGAGCGAAGAAACCAAAGCGAAAGCGGAAGAACTGCAGACGAAGG...  77.381690   \n",
       "255  ATGCAGGTGAAACTGGAAGAAAGCGGCGGCGGCAGCGTTCAAACTG...  77.637823   \n",
       "446  ATGAAAGATAAACTGAACGAACTGGCGAAACAGGCGATTGCGTATG...  87.471000   \n",
       "447  ATGAGCGCGGGCCAGGCGCAGATTGAAGAAGTGAAAGCGCGCGCAG...  89.580600   \n",
       "378  ATGCCGGATCTGCCGGGCTGCCCGCCGGAATTAGCGGGTTATTGTC...  41.997547   \n",
       "235  ATGCTGACCCTGCCGCCGAGCGCGCAGGCGCAGATCGAGCAGTTAA...  26.721833   \n",
       "62   ATGCATCATCATCATCATTGCCCGGCGAGCTATGATGGCTTTTGCC...  84.407925   \n",
       "57   ATGCATACCGAACGCCAGTGCCCGAGCAGCTATGATGGCTATTGCA...  86.462642   \n",
       "154  ATGTATGAAGTGAGCGCGCAGCAGAAACAACAAAAGACCAGCCGCC...  30.306500   \n",
       "224  ATGAAACTGGAAGAAATTAAAAAGAAACAGGAACTGGCGAACAAAC...  79.703494   \n",
       "318  ATGGGCCCGGCGCGCGAAGAAATTGAACGCCATACCGCGTTAGCAT...  79.757500   \n",
       "81   ATGCCGAGCTATAGCGCGTGCCCGAGCAGCTATGATGGCTATTGCG...  90.827000   \n",
       "114  ATGGATGAAGCGCGCAAACGCCTGGCGGCGAGCAACGCGAAAAACG...  27.680588   \n",
       "31   ATGGATGTGGAACGCTATAAGGAGACCCTGGAAGAAAGCAAAAAAG...  83.569875   \n",
       "453  ATGAAAGAAAAACTGAACGAACTGGCGGATGAAGCGATTAGCTTTG...  90.417200   \n",
       "9                                                  NaN        NaN   \n",
       "360  ATGGAAAAAGAAAGCCAGGAAATTATTAACCTGATCAGCAGCCTGA...  84.002000   \n",
       "\n",
       "     pae_interaction  similarity_check                     model_names  ...  \\\n",
       "262        27.569762          0.814000                        [\"ESM2\"]  ...   \n",
       "180        28.163272          0.976000                              []  ...   \n",
       "227        21.068868               NaN                 [\"ProteinMPNN\"]  ...   \n",
       "171        16.731577               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "20               NaN               NaN                             NaN  ...   \n",
       "362        15.236520               NaN                 [\"ProteinMPNN\"]  ...   \n",
       "85          7.919135          0.719100    [\"Custom (Active Learning)\"]  ...   \n",
       "46          9.333907          0.527744                 [\"ProteinMPNN\"]  ...   \n",
       "38         15.344847               NaN                              []  ...   \n",
       "441        23.642914               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "400        15.492161               NaN                              []  ...   \n",
       "334        13.452572               NaN                              []  ...   \n",
       "268        18.694262               NaN                              []  ...   \n",
       "403        15.909546               NaN                              []  ...   \n",
       "255        27.020995          0.806000                        [\"ESM2\"]  ...   \n",
       "446        15.706559               NaN                [\"AF2 Backprop\"]  ...   \n",
       "447        14.921833               NaN                [\"AF2 Backprop\"]  ...   \n",
       "378        20.797714          0.360220                 [\"ProteinMPNN\"]  ...   \n",
       "235        23.327960               NaN                 [\"ProteinMPNN\"]  ...   \n",
       "62          9.430105          0.509400                 [\"ProteinMPNN\"]  ...   \n",
       "57          9.042515          0.565936                 [\"ProteinMPNN\"]  ...   \n",
       "154        26.552847               NaN                              []  ...   \n",
       "224        18.945050               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "318        13.819649               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "81          8.043052          0.779520    [\"Custom (Active Learning)\"]  ...   \n",
       "114        22.689358               NaN                              []  ...   \n",
       "31         15.678809               NaN                              []  ...   \n",
       "453        16.367008               NaN                [\"AF2 Backprop\"]  ...   \n",
       "9                NaN               NaN                             NaN  ...   \n",
       "360        15.460188               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "\n",
       "           kd kon  koff  binding  confidence  expression  \\\n",
       "262       NaN NaN   NaN    False         low        high   \n",
       "180       NaN NaN   NaN  unknown         low         low   \n",
       "227       NaN NaN   NaN  unknown         low         low   \n",
       "171       NaN NaN   NaN  unknown         low         low   \n",
       "20        NaN NaN   NaN    false         NaN         NaN   \n",
       "362       NaN NaN   NaN    False         low        high   \n",
       "85        NaN NaN   NaN    False         low        high   \n",
       "46        NaN NaN   NaN    False         low        high   \n",
       "38        NaN NaN   NaN  unknown         low         low   \n",
       "441       NaN NaN   NaN    False         low        high   \n",
       "400       NaN NaN   NaN    False         low        high   \n",
       "334       NaN NaN   NaN    False         low        high   \n",
       "268       NaN NaN   NaN    False         low        high   \n",
       "403       NaN NaN   NaN    False         low        high   \n",
       "255       NaN NaN   NaN    False         low        high   \n",
       "446       NaN NaN   NaN    False         low        high   \n",
       "447  0.000005 NaN   NaN     True        high        high   \n",
       "378       NaN NaN   NaN    False         low      medium   \n",
       "235       NaN NaN   NaN  unknown         low         low   \n",
       "62        NaN NaN   NaN    False         low        high   \n",
       "57        NaN NaN   NaN  unknown         low         low   \n",
       "154       NaN NaN   NaN  unknown         low         low   \n",
       "224       NaN NaN   NaN    False         low         low   \n",
       "318       NaN NaN   NaN    False         low        high   \n",
       "81        NaN NaN   NaN    False         low        high   \n",
       "114       NaN NaN   NaN    False         low        high   \n",
       "31        NaN NaN   NaN    False         low        high   \n",
       "453       NaN NaN   NaN    False         low        high   \n",
       "9         NaN NaN   NaN    false         NaN         NaN   \n",
       "360       NaN NaN   NaN    False         low        high   \n",
       "\n",
       "    nc_adjusted_expression length binding_strength encoded_expression  \n",
       "262                   high  124.0              NaN                  3  \n",
       "180                   none  127.0              NaN                  0  \n",
       "227                   none   60.0              NaN                  0  \n",
       "171                   none   91.0              NaN                  0  \n",
       "20                    high    NaN             none                  3  \n",
       "362                   high   20.0              NaN                  3  \n",
       "85                    high   50.0              NaN                  3  \n",
       "46                    high   53.0              NaN                  3  \n",
       "38                    none  130.0              NaN                  0  \n",
       "441                   high  100.0              NaN                  3  \n",
       "400                   high   71.0              NaN                  3  \n",
       "334                   high   43.0              NaN                  3  \n",
       "268                   high   71.0              NaN                  3  \n",
       "403                   high   71.0              NaN                  3  \n",
       "255                   high  124.0              NaN                  3  \n",
       "446                   high  100.0              NaN                  3  \n",
       "447                   high  100.0              NaN                  3  \n",
       "378                 medium   53.0              NaN                  2  \n",
       "235                   none   60.0              NaN                  0  \n",
       "62                    high   53.0              NaN                  3  \n",
       "57                    none   53.0              NaN                  0  \n",
       "154                   none  200.0              NaN                  0  \n",
       "224                    low   83.0              NaN                  1  \n",
       "318                   high   80.0              NaN                  3  \n",
       "81                    high   50.0              NaN                  3  \n",
       "114                   high   51.0              NaN                  3  \n",
       "31                    high   80.0              NaN                  3  \n",
       "453                   high  100.0              NaN                  3  \n",
       "9                     high    NaN             none                  3  \n",
       "360                   high   80.0              NaN                  3  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>KD</th>\n",
       "      <th>sequence_x</th>\n",
       "      <th>dna</th>\n",
       "      <th>plddt</th>\n",
       "      <th>pae_interaction</th>\n",
       "      <th>similarity_check</th>\n",
       "      <th>model_names</th>\n",
       "      <th>...</th>\n",
       "      <th>length</th>\n",
       "      <th>p_soluble</th>\n",
       "      <th>replicate_y</th>\n",
       "      <th>nc_adjusted_expression_y</th>\n",
       "      <th>binding_y</th>\n",
       "      <th>kd_y</th>\n",
       "      <th>kon_y</th>\n",
       "      <th>koff_y</th>\n",
       "      <th>sequence_y</th>\n",
       "      <th>binding_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cetuximab_scFv</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6.638345e-09</td>\n",
       "      <td>QVQLKQSGPGLVQPSQSLSITCTVSGFSLTNYGVHWVRQSPGKGLE...</td>\n",
       "      <td>ATGCAGGTGCAGCTGAAACAGAGCGGCCCGGGCCTGGTGCAGCCAT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.275504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01133-971-1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>9.598217e-08</td>\n",
       "      <td>70048.032467</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01133-971-1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>7.399160e-08</td>\n",
       "      <td>70316.606870</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01133-971-1023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>high</td>\n",
       "      <td>true</td>\n",
       "      <td>1.084595e-07</td>\n",
       "      <td>71749.349728</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Razora712-sequence_10</td>\n",
       "      <td>Razora712</td>\n",
       "      <td>sequence_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EELKKALQALKKEYRDKQWAVVQEMLKQHAEIAKKKEAGEINEKEA...</td>\n",
       "      <td>ATGGAAGAACTGAAAAAAGCGCTGCAGGCGTTAAAGAAGGAATATC...</td>\n",
       "      <td>84.399867</td>\n",
       "      <td>15.981933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>x.rustamov-s_11_5</td>\n",
       "      <td>x.rustamov</td>\n",
       "      <td>s_11_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MPELEAFKEEFEKFMKEFKKLSEEDIKDFKENLKKKGKPVTEEDIE...</td>\n",
       "      <td>ATGCCGGAACTGGAAGCGTTTAAGGAAGAGTTCGAAAAGTTTATGA...</td>\n",
       "      <td>83.292000</td>\n",
       "      <td>13.936515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"AF2 Backprop\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.985808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>x.rustamov-s_15_28</td>\n",
       "      <td>x.rustamov</td>\n",
       "      <td>s_15_28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKEKLNELADEAISFAKSIFGDHPSLATFTSFANSVADDLSKEDIS...</td>\n",
       "      <td>ATGAAAGAAAAACTGAACGAACTGGCGGATGAAGCGATTAGCTTTG...</td>\n",
       "      <td>90.417200</td>\n",
       "      <td>16.367008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"AF2 Backprop\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.810916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>zalavi-egfr_binder3</td>\n",
       "      <td>zalavi</td>\n",
       "      <td>egfr_binder3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEEAKELKEKAKEKLKEALEKAKEALKDAEKAAEILKKIPEAKEAL...</td>\n",
       "      <td>ATGAGCGAAGAAGCGAAAGAACTGAAAGAAAAAGCGAAGGAAAAGT...</td>\n",
       "      <td>94.207733</td>\n",
       "      <td>13.780420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.996674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>zalavi-egfr_binder7</td>\n",
       "      <td>zalavi</td>\n",
       "      <td>egfr_binder7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AQAAAKETIRAVLKAAAEAARKMAEEARKLAKELEKYNKEAAKHAL...</td>\n",
       "      <td>ATGGCGCAGGCGGCGGCGAAAGAAACCATTCGCGCGGTTTTAAAAG...</td>\n",
       "      <td>92.160077</td>\n",
       "      <td>14.556357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.990431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>zalavi-egfr_binder8</td>\n",
       "      <td>zalavi</td>\n",
       "      <td>egfr_binder8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IDEKKKEEYESLATELNAQAKALKAQADATGSQTYANFATAASDAA...</td>\n",
       "      <td>ATGATTGATGAAAAGAAAAAAGAAGAATACGAAAGCCTGGCGACCG...</td>\n",
       "      <td>85.588750</td>\n",
       "      <td>13.611997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"RFdiffusion\", \"ProteinMPNN\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.985279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name    username sequence_name            KD  \\\n",
       "0           Cetuximab_scFv        None          None  6.638345e-09   \n",
       "1          P01133-971-1023         NaN           NaN           NaN   \n",
       "2          P01133-971-1023         NaN           NaN           NaN   \n",
       "3          P01133-971-1023         NaN           NaN           NaN   \n",
       "4    Razora712-sequence_10   Razora712   sequence_10           NaN   \n",
       "..                     ...         ...           ...           ...   \n",
       "230      x.rustamov-s_11_5  x.rustamov        s_11_5           NaN   \n",
       "231     x.rustamov-s_15_28  x.rustamov       s_15_28           NaN   \n",
       "232    zalavi-egfr_binder3      zalavi  egfr_binder3           NaN   \n",
       "233    zalavi-egfr_binder7      zalavi  egfr_binder7           NaN   \n",
       "234    zalavi-egfr_binder8      zalavi  egfr_binder8           NaN   \n",
       "\n",
       "                                            sequence_x  \\\n",
       "0    QVQLKQSGPGLVQPSQSLSITCTVSGFSLTNYGVHWVRQSPGKGLE...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    EELKKALQALKKEYRDKQWAVVQEMLKQHAEIAKKKEAGEINEKEA...   \n",
       "..                                                 ...   \n",
       "230  MPELEAFKEEFEKFMKEFKKLSEEDIKDFKENLKKKGKPVTEEDIE...   \n",
       "231  MKEKLNELADEAISFAKSIFGDHPSLATFTSFANSVADDLSKEDIS...   \n",
       "232  SEEAKELKEKAKEKLKEALEKAKEALKDAEKAAEILKKIPEAKEAL...   \n",
       "233  AQAAAKETIRAVLKAAAEAARKMAEEARKLAKELEKYNKEAAKHAL...   \n",
       "234  IDEKKKEEYESLATELNAQAKALKAQADATGSQTYANFATAASDAA...   \n",
       "\n",
       "                                                   dna      plddt  \\\n",
       "0    ATGCAGGTGCAGCTGAAACAGAGCGGCCCGGGCCTGGTGCAGCCAT...        NaN   \n",
       "1                                                  NaN        NaN   \n",
       "2                                                  NaN        NaN   \n",
       "3                                                  NaN        NaN   \n",
       "4    ATGGAAGAACTGAAAAAAGCGCTGCAGGCGTTAAAGAAGGAATATC...  84.399867   \n",
       "..                                                 ...        ...   \n",
       "230  ATGCCGGAACTGGAAGCGTTTAAGGAAGAGTTCGAAAAGTTTATGA...  83.292000   \n",
       "231  ATGAAAGAAAAACTGAACGAACTGGCGGATGAAGCGATTAGCTTTG...  90.417200   \n",
       "232  ATGAGCGAAGAAGCGAAAGAACTGAAAGAAAAAGCGAAGGAAAAGT...  94.207733   \n",
       "233  ATGGCGCAGGCGGCGGCGAAAGAAACCATTCGCGCGGTTTTAAAAG...  92.160077   \n",
       "234  ATGATTGATGAAAAGAAAAAAGAAGAATACGAAAGCCTGGCGACCG...  85.588750   \n",
       "\n",
       "     pae_interaction  similarity_check                     model_names  ...  \\\n",
       "0                NaN               NaN                            None  ...   \n",
       "1                NaN               NaN                             NaN  ...   \n",
       "2                NaN               NaN                             NaN  ...   \n",
       "3                NaN               NaN                             NaN  ...   \n",
       "4          15.981933               NaN                              []  ...   \n",
       "..               ...               ...                             ...  ...   \n",
       "230        13.936515               NaN                [\"AF2 Backprop\"]  ...   \n",
       "231        16.367008               NaN                [\"AF2 Backprop\"]  ...   \n",
       "232        13.780420               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "233        14.556357               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "234        13.611997               NaN  [\"RFdiffusion\", \"ProteinMPNN\"]  ...   \n",
       "\n",
       "    length p_soluble  replicate_y  nc_adjusted_expression_y  binding_y  \\\n",
       "0    241.0  0.275504          NaN                       NaN        NaN   \n",
       "1      NaN       NaN          1.0                      high       true   \n",
       "2      NaN       NaN          2.0                      high       true   \n",
       "3      NaN       NaN          3.0                      high       true   \n",
       "4     75.0  0.997512          NaN                       NaN        NaN   \n",
       "..     ...       ...          ...                       ...        ...   \n",
       "230  100.0  0.985808          NaN                       NaN        NaN   \n",
       "231  100.0  0.810916          NaN                       NaN        NaN   \n",
       "232  150.0  0.996674          NaN                       NaN        NaN   \n",
       "233  130.0  0.990431          NaN                       NaN        NaN   \n",
       "234   56.0  0.985279          NaN                       NaN        NaN   \n",
       "\n",
       "             kd_y         kon_y    koff_y  \\\n",
       "0             NaN           NaN       NaN   \n",
       "1    9.598217e-08  70048.032467  0.006723   \n",
       "2    7.399160e-08  70316.606870  0.005203   \n",
       "3    1.084595e-07  71749.349728  0.007782   \n",
       "4             NaN           NaN       NaN   \n",
       "..            ...           ...       ...   \n",
       "230           NaN           NaN       NaN   \n",
       "231           NaN           NaN       NaN   \n",
       "232           NaN           NaN       NaN   \n",
       "233           NaN           NaN       NaN   \n",
       "234           NaN           NaN       NaN   \n",
       "\n",
       "                                            sequence_y binding_strength  \n",
       "0                                                  NaN              NaN  \n",
       "1    NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...           medium  \n",
       "2    NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...           medium  \n",
       "3    NSDSECPLSHDGYCLHDGVCMYIEALDKYACNCVVGYIGERCQYRD...           medium  \n",
       "4                                                  NaN              NaN  \n",
       "..                                                 ...              ...  \n",
       "230                                                NaN              NaN  \n",
       "231                                                NaN              NaN  \n",
       "232                                                NaN              NaN  \n",
       "233                                                NaN              NaN  \n",
       "234                                                NaN              NaN  \n",
       "\n",
       "[235 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.merge(gdf.rename(columns={'expression': 'nc_adjusted_expression'}), how='outer', on='name')\n",
    "# df = df.drop_duplicates(subset=['name', 'sequence']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['name', 'sequence']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rd1.fasta', 'w') as fasta_file:\n",
    "    for _, row in df.iterrows():\n",
    "        binder = row['sequence']\n",
    "        complex = f'{binder}:{egfr.EGFR}'\n",
    "        name = row['name']\n",
    "        \n",
    "        # Write binder sequence\n",
    "        fasta_file.write(f'>{name}\\n{complex}\\n')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p_soluble'] = df['sequence'].apply(calculate_solubility)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/seaborn/categorical.py:3399: UserWarning: 22.9% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='p_soluble', ylabel='nc_adjusted_expression'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/seaborn/categorical.py:3399: UserWarning: 26.7% of the points cannot be placed; you may want to decrease the size of the markers or use stripplot.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.swarmplot(x='p_soluble', y='nc_adjusted_expression', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-04 08:57:58,758 - INFO - Enabling RDKit 2024.03.5 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import wandb\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import logging\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from transformers import EsmForMaskedLM, AutoTokenizer\n",
    "\n",
    "\n",
    "from egfr_binder_rd2.datamodule import SequenceDataModule, SequenceFeaturesDataModule\n",
    "from egfr_binder_rd2.bt import PartialEnsembleModuleWithFeatures\n",
    "from egfr_binder_rd2.binding_dataset import get_dataset\n",
    "import egfr_binder_rd2 as egfr\n",
    "from egfr_binder_rd2.expression_dataset import get_data, get_by_seq_data, create_data_splits_grouped\n",
    "from egfr_binder_rd2.solubility import calculate_solubility\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "seed = 42\n",
    "debug = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:57:59,227 - INFO - HTTP Request: GET https://polarishub.io/api/v1/dataset/adaptyv-bio/egfr-binders-v0 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:57:59,573 - INFO - HTTP Request: GET https://polarishub.io/storage/dataset/adaptyv-bio/egfr-binders-v0/table.parquet \"HTTP/1.1 307 Temporary Redirect\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Fetching artifact... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 08:57:59,830 - INFO - HTTP Request: GET https://874f02b9d981bd6c279e979c0d91c4b4.r2.cloudflarestorage.com/polaris/dataset/adaptyv-bio/egfr-binders-v0/table.parquet?X-Amz-Expires=3600&X-Amz-Date=20241104T165759Z&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=810f02be0d7621779492bf8c1c1de2ce%2F20241104%2Fauto%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Signature=a45ac4e69013534aa333343acc195c310257b4f7523c1ca644d8a9f4cf2d3274 \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2024-11-04 08:57:59.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris._artifact\u001b[0m:\u001b[36m_validate_version\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mThe version of Polaris that was used to create the artifact (0.8.7.dev1+g23fd61e.d20240926) is different from the currently installed version of Polaris (0.8.6).\u001b[0m\n",
      "\u001b[32m2024-11-04 08:57:59.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpolaris.mixins._checksum\u001b[0m:\u001b[36mverify_checksum\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mTo verify the checksum, we need to recompute it. This can be slow for large datasets.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SUCCESS: \u001b[1mFetched artifact.\u001b[0m\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/yaspin/core.py:239: UserWarning: color, on_color and attrs are not supported when running in jupyter\n",
      "  self._color = self._set_color(value) if value else value\n"
     ]
    }
   ],
   "source": [
    "df = get_by_seq_data()\n",
    "split_df = create_data_splits_grouped(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label: str\n",
    "# model_name: str = \"facebook/esm2_t33_650M_UR50D\"\n",
    "model_name: str = \"facebook/esm2_t6_8M_UR50D\"\n",
    "lr: float = 5e-4\n",
    "peft_r: int = 8\n",
    "peft_alpha: int = 16\n",
    "max_length: int = 512\n",
    "yvar = 'encoded_expression'\n",
    "xvar = 'sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 6342.21 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4564.73 examples/s]\n",
      "Map: 100%|██████████| 21/21 [00:00<00:00, 4861.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and setup the DataModule\n",
    "data_module = SequenceDataModule(\n",
    "    df, \n",
    "    tokenizer_name=\"facebook/esm2_t33_650M_UR50D\",\n",
    "    xvar=xvar,\n",
    "    yvar=yvar,  # You can change this to any other column name in your DataFrame\n",
    "    batch_size=32,\n",
    "    max_length=512,\n",
    "    transform_type='standardize',\n",
    "    make_negative=False,\n",
    ")\n",
    "data_module.setup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/naka/code/egfr_binder_rd2/.venv/lib/python3.11 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 7226.57 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4337.66 examples/s]\n",
      "Map: 100%|██████████| 21/21 [00:00<00:00, 4897.16 examples/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                          | Params | Mode \n",
      "-----------------------------------------------------------------------------\n",
      "0 | esm_model          | PeftModelForFeatureExtraction | 7.9 M  | train\n",
      "1 | ensemble_heads     | ModuleList                    | 1.1 K  | train\n",
      "2 | train_metrics      | MetricCollection              | 0      | train\n",
      "3 | val_mae            | MeanAbsoluteError             | 0      | train\n",
      "4 | val_spearman       | SpearmanCorrCoef              | 0      | train\n",
      "5 | bt_loss            | BradleyTerryLoss              | 0      | train\n",
      "6 | mse_loss           | MSELoss                       | 0      | train\n",
      "7 | feature_projection | Sequential                    | 224    | train\n",
      "-----------------------------------------------------------------------------\n",
      "93.4 K    Trainable params\n",
      "7.8 M     Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.734    Total estimated model params size (MB)\n",
      "197       Modules in train mode\n",
      "122       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  60%|██████    | 3/5 [00:01<00:00,  2.37it/s, v_num=ih1w]        \n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = PartialEnsembleModuleWithFeatures(\n",
    "    label=yvar,\n",
    "    num_heads=3,  # Number of ensemble heads\n",
    "    model_name=model_name,\n",
    "    lr=lr,\n",
    "    peft_r=peft_r,\n",
    "    peft_alpha=peft_alpha,\n",
    "    max_length=max_length,\n",
    "    dropout=0.,\n",
    "    xvar=xvar,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor='val_spearman',\n",
    "            mode='max',\n",
    "            patience=25,\n",
    "            min_delta=0.001\n",
    "        )\n",
    "    ],\n",
    "    logger=WandbLogger(project='egfr_binder_rd2_pe_scratch'),\n",
    "    precision='32-true',\n",
    "    log_every_n_steps=2,\n",
    "    enable_checkpointing=False,\n",
    "    val_check_interval=0.25,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    datamodule=data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 160/160 [00:00<00:00, 7513.39 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4500.33 examples/s]\n",
      "Map: 100%|██████████| 21/21 [00:00<00:00, 5002.86 examples/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 5/5 [00:00<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 160/160 [00:00<00:00, 7531.94 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4242.67 examples/s]\n",
      "Map: 100%|██████████| 21/21 [00:00<00:00, 5081.66 examples/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 160/160 [00:00<00:00, 7578.81 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4360.21 examples/s]\n",
      "Map: 100%|██████████| 21/21 [00:00<00:00, 4979.95 examples/s]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s]\n",
      "\n",
      "Results by split:\n",
      "train split correlation: 0.877\n",
      "val split correlation: 0.614\n",
      "test split correlation: 0.535\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for all splits\n",
    "predictions = {\n",
    "    'train': trainer.predict(model, dataloaders=data_module.train_dataloader(shuffle=False)),\n",
    "    'val': trainer.predict(model, dataloaders=data_module.val_dataloader()),\n",
    "    'test': trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
    "}\n",
    "\n",
    "# Combine predictions\n",
    "results = {\n",
    "    'sequence': [],\n",
    "    'prediction': [],  # ensemble mean\n",
    "    'uncertainty': [], # ensemble std\n",
    "    'target': [],\n",
    "    'split': [],  # Track which split each prediction came from\n",
    "}\n",
    "\n",
    "# Add columns for each head\n",
    "num_heads = model.hparams.num_heads\n",
    "for i in range(num_heads):\n",
    "    results[f'head_{i}'] = []\n",
    "\n",
    "# Process predictions from each split\n",
    "for split_name, split_predictions in predictions.items():\n",
    "    for batch in split_predictions:\n",
    "        sequences = batch['sequence']\n",
    "        results['sequence'].extend(sequences)\n",
    "        results['split'].extend([split_name] * len(sequences))\n",
    "        \n",
    "        # Handle ensemble predictions and uncertainties\n",
    "        pred = batch['predictions'].cpu().numpy()\n",
    "        unc = batch['uncertainties'].cpu().numpy()\n",
    "        target = batch['target'].cpu().numpy()\n",
    "        if pred.ndim > 1:\n",
    "            pred = pred.squeeze()\n",
    "        if unc.ndim > 1:\n",
    "            unc = unc.squeeze()\n",
    "        if target.ndim > 1:\n",
    "            target = target.squeeze()\n",
    "        results['prediction'].extend(pred.reshape(-1))\n",
    "        results['uncertainty'].extend(unc.reshape(-1))\n",
    "        results['target'].extend(target.reshape(-1))\n",
    "\n",
    "        # Handle individual head predictions\n",
    "        head_preds = batch['head_predictions'].cpu().numpy()\n",
    "        if head_preds.ndim > 1:\n",
    "            head_preds = head_preds.squeeze()\n",
    "        if head_preds.ndim == 1:  # Single sample\n",
    "            head_preds = head_preds.reshape(1, -1)\n",
    "        \n",
    "        # Add each head's predictions\n",
    "        for i in range(num_heads):\n",
    "            results[f'head_{i}'].extend(head_preds[:, i])\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Now you can analyze results by split\n",
    "print(\"\\nResults by split:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_df = results_df[results_df['split'] == split]\n",
    "    correlation = spearmanr(split_df['prediction'], split_df['target']).correlation\n",
    "    print(f\"{split} split correlation: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target', ylabel='value'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "melted = results_df.melt(id_vars=['sequence', 'prediction', 'target', 'uncertainty', 'split'])\n",
    "sns.scatterplot(melted.query('split == \"test\"'), x='target', y='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: expression_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adapter_state_dict': {'base_model.model.encoder.layer.0.attention.self.query.lora_A.weight': tensor([[ 0.0297, -0.0829, -0.0417,  ...,  0.0755, -0.0098, -0.0204],\n",
       "          [ 0.0369, -0.0069, -0.0302,  ...,  0.0380, -0.0226,  0.0032],\n",
       "          [ 0.0645,  0.0240,  0.0480,  ..., -0.0677, -0.0269, -0.0288],\n",
       "          ...,\n",
       "          [ 0.0496,  0.0665,  0.0447,  ..., -0.0611, -0.0329,  0.0110],\n",
       "          [-0.0266, -0.0602, -0.0007,  ...,  0.0073, -0.0735, -0.0302],\n",
       "          [ 0.0334, -0.0570,  0.0073,  ...,  0.0416, -0.0495, -0.0149]]),\n",
       "  'base_model.model.encoder.layer.0.attention.self.query.lora_B.weight': tensor([[-0.0161, -0.0244,  0.0173,  ...,  0.0150, -0.0062, -0.0017],\n",
       "          [ 0.0127,  0.0121, -0.0024,  ..., -0.0102,  0.0228,  0.0160],\n",
       "          [ 0.0061,  0.0031,  0.0005,  ..., -0.0060,  0.0238,  0.0174],\n",
       "          ...,\n",
       "          [-0.0095, -0.0199,  0.0172,  ...,  0.0079, -0.0160, -0.0086],\n",
       "          [ 0.0024,  0.0098, -0.0109,  ..., -0.0056,  0.0034,  0.0061],\n",
       "          [-0.0009,  0.0077, -0.0074,  ..., -0.0025, -0.0015, -0.0024]]),\n",
       "  'base_model.model.encoder.layer.0.attention.self.key.lora_A.weight': tensor([[-0.0170,  0.0259, -0.0262,  ..., -0.0527, -0.0688, -0.0262],\n",
       "          [ 0.0440, -0.0053, -0.0161,  ...,  0.0556,  0.0142,  0.0043],\n",
       "          [-0.0224,  0.0767, -0.0646,  ..., -0.0850,  0.0149, -0.0242],\n",
       "          ...,\n",
       "          [-0.0172, -0.0238, -0.0733,  ...,  0.0122, -0.0305,  0.0594],\n",
       "          [ 0.0033,  0.0154,  0.0231,  ...,  0.0011, -0.0128,  0.0036],\n",
       "          [-0.0339, -0.0163, -0.0003,  ..., -0.0326,  0.0461, -0.0082]]),\n",
       "  'base_model.model.encoder.layer.0.attention.self.key.lora_B.weight': tensor([[ 0.0010,  0.0124, -0.0099,  ...,  0.0142,  0.0114,  0.0050],\n",
       "          [-0.0321,  0.0006,  0.0165,  ...,  0.0153, -0.0148, -0.0098],\n",
       "          [-0.0036,  0.0315,  0.0017,  ...,  0.0015, -0.0042,  0.0108],\n",
       "          ...,\n",
       "          [-0.0181, -0.0227,  0.0191,  ..., -0.0156,  0.0034, -0.0083],\n",
       "          [-0.0183, -0.0024,  0.0068,  ..., -0.0104,  0.0007,  0.0044],\n",
       "          [ 0.0117,  0.0079, -0.0015,  ...,  0.0066, -0.0127,  0.0097]]),\n",
       "  'base_model.model.encoder.layer.0.attention.self.value.lora_A.weight': tensor([[ 0.0133,  0.0123,  0.0394,  ..., -0.0260, -0.0520, -0.0096],\n",
       "          [-0.0499, -0.0479, -0.0082,  ..., -0.0657,  0.0596, -0.0371],\n",
       "          [-0.0030, -0.0267, -0.0396,  ..., -0.0458, -0.0004, -0.0025],\n",
       "          ...,\n",
       "          [ 0.0425,  0.0566, -0.0145,  ..., -0.0350,  0.0309, -0.0296],\n",
       "          [ 0.0574,  0.0507, -0.0022,  ...,  0.0038, -0.0181, -0.0287],\n",
       "          [-0.0714, -0.0399,  0.0233,  ..., -0.0094,  0.0011,  0.0300]]),\n",
       "  'base_model.model.encoder.layer.0.attention.self.value.lora_B.weight': tensor([[-0.0166,  0.0131, -0.0018,  ..., -0.0059,  0.0026,  0.0048],\n",
       "          [ 0.0201,  0.0128,  0.0224,  ..., -0.0193, -0.0198,  0.0207],\n",
       "          [-0.0192,  0.0032, -0.0085,  ...,  0.0046,  0.0100, -0.0064],\n",
       "          ...,\n",
       "          [-0.0009,  0.0145,  0.0047,  ..., -0.0078, -0.0064,  0.0092],\n",
       "          [ 0.0105,  0.0247,  0.0142,  ..., -0.0131, -0.0140,  0.0133],\n",
       "          [ 0.0009,  0.0159,  0.0039,  ..., -0.0095, -0.0068,  0.0113]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.query.lora_A.weight': tensor([[-0.0208,  0.0036,  0.0232,  ..., -0.0149,  0.0162, -0.0298],\n",
       "          [ 0.0438, -0.0213, -0.0195,  ...,  0.0165, -0.0100,  0.0414],\n",
       "          [-0.0482,  0.0463,  0.0440,  ..., -0.0561,  0.0491, -0.0140],\n",
       "          ...,\n",
       "          [-0.0432,  0.0030, -0.0547,  ..., -0.0282,  0.0445, -0.0261],\n",
       "          [-0.0120, -0.0005,  0.0615,  ...,  0.0666,  0.0369,  0.0054],\n",
       "          [-0.0326, -0.0172,  0.0103,  ...,  0.0440, -0.0362,  0.0368]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.query.lora_B.weight': tensor([[ 0.0214,  0.0082,  0.0056,  ...,  0.0039, -0.0134,  0.0133],\n",
       "          [ 0.0072, -0.0029, -0.0004,  ..., -0.0011, -0.0020,  0.0033],\n",
       "          [-0.0189, -0.0126, -0.0134,  ...,  0.0159,  0.0128, -0.0129],\n",
       "          ...,\n",
       "          [-0.0062,  0.0124,  0.0070,  ..., -0.0085,  0.0094,  0.0084],\n",
       "          [-0.0018,  0.0113,  0.0045,  ..., -0.0058,  0.0094,  0.0050],\n",
       "          [-0.0039, -0.0017, -0.0031,  ...,  0.0030, -0.0030, -0.0053]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.key.lora_A.weight': tensor([[ 0.0460, -0.0219,  0.0144,  ..., -0.0158,  0.0604, -0.0214],\n",
       "          [-0.0312,  0.0296, -0.0409,  ..., -0.0551, -0.0339, -0.0700],\n",
       "          [ 0.0034, -0.0315, -0.0374,  ..., -0.0388, -0.0553, -0.0279],\n",
       "          ...,\n",
       "          [ 0.0076, -0.0120,  0.0258,  ..., -0.0347, -0.0290,  0.0248],\n",
       "          [ 0.0438,  0.0123, -0.0343,  ..., -0.0245, -0.0044, -0.0587],\n",
       "          [ 0.0463, -0.0476,  0.0332,  ..., -0.0417,  0.0334, -0.0430]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.key.lora_B.weight': tensor([[ 0.0004,  0.0091, -0.0174,  ..., -0.0073, -0.0101, -0.0097],\n",
       "          [ 0.0014, -0.0082, -0.0232,  ..., -0.0120, -0.0162, -0.0212],\n",
       "          [-0.0002,  0.0023,  0.0218,  ...,  0.0245,  0.0062,  0.0168],\n",
       "          ...,\n",
       "          [ 0.0180,  0.0006, -0.0015,  ...,  0.0064, -0.0029, -0.0185],\n",
       "          [ 0.0089,  0.0010,  0.0067,  ..., -0.0065, -0.0008,  0.0048],\n",
       "          [ 0.0062, -0.0078,  0.0036,  ...,  0.0161,  0.0118, -0.0062]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.value.lora_A.weight': tensor([[ 0.0330, -0.0135, -0.0180,  ..., -0.0079,  0.0498,  0.0256],\n",
       "          [-0.0352,  0.0002, -0.0833,  ..., -0.0130, -0.0204, -0.0290],\n",
       "          [-0.0057,  0.0662,  0.0753,  ..., -0.0358,  0.0121,  0.0223],\n",
       "          ...,\n",
       "          [-0.0113,  0.0264,  0.0556,  ...,  0.0418, -0.0051,  0.0032],\n",
       "          [-0.0742, -0.0550, -0.0636,  ...,  0.0304,  0.0008,  0.0162],\n",
       "          [-0.0016,  0.0011,  0.0208,  ..., -0.0548,  0.0477, -0.0439]]),\n",
       "  'base_model.model.encoder.layer.1.attention.self.value.lora_B.weight': tensor([[-1.9689e-03, -1.0698e-02,  9.8470e-03,  ...,  5.0546e-03,\n",
       "           -8.9480e-03, -1.0434e-02],\n",
       "          [-1.1427e-02, -9.4543e-03,  2.5513e-05,  ..., -1.1140e-02,\n",
       "           -1.5662e-02, -1.3802e-02],\n",
       "          [-7.6839e-03,  3.4225e-03, -8.7318e-03,  ..., -1.8515e-03,\n",
       "            7.1520e-03,  1.6253e-03],\n",
       "          ...,\n",
       "          [ 1.2483e-02,  2.6497e-04,  4.0512e-03,  ...,  3.3307e-03,\n",
       "            1.1917e-03,  3.9026e-03],\n",
       "          [-6.4073e-03,  3.8161e-03, -8.6956e-03,  ...,  2.7557e-03,\n",
       "            1.0121e-02,  7.4204e-04],\n",
       "          [-1.6113e-02,  1.9828e-02, -2.2891e-02,  ..., -2.4317e-02,\n",
       "            1.9563e-02,  1.0313e-04]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.query.lora_A.weight': tensor([[ 0.0273,  0.0231,  0.0365,  ..., -0.0441, -0.0287, -0.0031],\n",
       "          [-0.0432,  0.0101,  0.0331,  ...,  0.0396, -0.0362,  0.0213],\n",
       "          [-0.0651,  0.0373, -0.0492,  ..., -0.0249,  0.0406,  0.0383],\n",
       "          ...,\n",
       "          [ 0.0278, -0.0637, -0.0539,  ...,  0.0422, -0.0221,  0.0062],\n",
       "          [ 0.0490,  0.0063,  0.0386,  ..., -0.0603, -0.0407,  0.0082],\n",
       "          [-0.0079, -0.0617, -0.0744,  ..., -0.0232, -0.0312,  0.0105]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.query.lora_B.weight': tensor([[-0.0032, -0.0118, -0.0184,  ...,  0.0080, -0.0044,  0.0005],\n",
       "          [ 0.0099,  0.0203,  0.0214,  ..., -0.0191,  0.0185, -0.0072],\n",
       "          [-0.0072,  0.0017, -0.0005,  ...,  0.0032,  0.0021,  0.0004],\n",
       "          ...,\n",
       "          [ 0.0085,  0.0182,  0.0171,  ..., -0.0116,  0.0159, -0.0120],\n",
       "          [-0.0124, -0.0082, -0.0112,  ...,  0.0157, -0.0111,  0.0077],\n",
       "          [ 0.0064,  0.0073,  0.0006,  ..., -0.0048,  0.0058,  0.0006]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.key.lora_A.weight': tensor([[-0.0428, -0.0488,  0.0131,  ..., -0.0029, -0.0219,  0.0311],\n",
       "          [ 0.0346, -0.0024, -0.0336,  ...,  0.0119,  0.0157,  0.0582],\n",
       "          [-0.0506,  0.0468,  0.0063,  ..., -0.0167, -0.0394,  0.0394],\n",
       "          ...,\n",
       "          [ 0.0230,  0.0287,  0.0393,  ..., -0.0105, -0.0479, -0.0432],\n",
       "          [-0.0228, -0.0449, -0.0267,  ...,  0.0633,  0.0706, -0.0539],\n",
       "          [ 0.0120, -0.0156,  0.0059,  ...,  0.0692,  0.0183,  0.0329]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.key.lora_B.weight': tensor([[-0.0105,  0.0087, -0.0097,  ...,  0.0098,  0.0022, -0.0036],\n",
       "          [-0.0095,  0.0134, -0.0058,  ...,  0.0078,  0.0188, -0.0076],\n",
       "          [-0.0323,  0.0229, -0.0237,  ..., -0.0203,  0.0064,  0.0266],\n",
       "          ...,\n",
       "          [ 0.0040, -0.0039,  0.0136,  ..., -0.0043, -0.0173, -0.0079],\n",
       "          [ 0.0146,  0.0085,  0.0193,  ..., -0.0165, -0.0259, -0.0021],\n",
       "          [ 0.0094, -0.0072,  0.0161,  ..., -0.0068, -0.0206, -0.0172]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.value.lora_A.weight': tensor([[ 0.0386, -0.0632,  0.0455,  ...,  0.0277,  0.0709,  0.0166],\n",
       "          [-0.0292, -0.0464,  0.0161,  ...,  0.0461,  0.0001,  0.0020],\n",
       "          [-0.0067,  0.0140, -0.0417,  ...,  0.0484, -0.0040, -0.0638],\n",
       "          ...,\n",
       "          [-0.0732, -0.0397,  0.0289,  ...,  0.0155,  0.0331, -0.0477],\n",
       "          [-0.0026, -0.0055,  0.0181,  ..., -0.0065, -0.0604, -0.0252],\n",
       "          [-0.0046,  0.0043,  0.0708,  ...,  0.0033,  0.0092,  0.0549]]),\n",
       "  'base_model.model.encoder.layer.2.attention.self.value.lora_B.weight': tensor([[-0.0143, -0.0091, -0.0146,  ..., -0.0133,  0.0124,  0.0124],\n",
       "          [-0.0050, -0.0024, -0.0029,  ..., -0.0054,  0.0055,  0.0056],\n",
       "          [ 0.0079,  0.0103,  0.0082,  ...,  0.0025, -0.0084, -0.0131],\n",
       "          ...,\n",
       "          [-0.0041, -0.0054, -0.0022,  ...,  0.0036,  0.0107, -0.0009],\n",
       "          [ 0.0305,  0.0254,  0.0266,  ...,  0.0240, -0.0268, -0.0196],\n",
       "          [-0.0072, -0.0085, -0.0029,  ...,  0.0088,  0.0119,  0.0119]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.query.lora_A.weight': tensor([[-0.0209, -0.0408,  0.0199,  ...,  0.0098, -0.0143,  0.0664],\n",
       "          [ 0.0556,  0.0421, -0.0597,  ..., -0.0436,  0.0401, -0.0583],\n",
       "          [ 0.0205,  0.0156, -0.0340,  ...,  0.0587, -0.0160, -0.0289],\n",
       "          ...,\n",
       "          [-0.0284,  0.0306,  0.0701,  ...,  0.0418,  0.0242, -0.0121],\n",
       "          [ 0.0252, -0.0157,  0.0100,  ..., -0.0079, -0.0320, -0.0081],\n",
       "          [ 0.0185,  0.0282,  0.0385,  ..., -0.0546, -0.0355, -0.0451]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.query.lora_B.weight': tensor([[ 0.0120, -0.0042,  0.0085,  ...,  0.0111, -0.0060, -0.0143],\n",
       "          [ 0.0100, -0.0187,  0.0162,  ...,  0.0167, -0.0115, -0.0218],\n",
       "          [-0.0261,  0.0102, -0.0076,  ..., -0.0049,  0.0177,  0.0147],\n",
       "          ...,\n",
       "          [-0.0127,  0.0168, -0.0210,  ..., -0.0200,  0.0086,  0.0137],\n",
       "          [-0.0063,  0.0199, -0.0137,  ..., -0.0082,  0.0172,  0.0167],\n",
       "          [ 0.0189, -0.0091,  0.0094,  ...,  0.0079, -0.0166, -0.0055]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.key.lora_A.weight': tensor([[-0.0293,  0.0437, -0.0200,  ..., -0.0426,  0.0587, -0.0696],\n",
       "          [-0.0073,  0.0133,  0.0761,  ..., -0.0038, -0.0014,  0.0443],\n",
       "          [-0.0179, -0.0157, -0.0410,  ...,  0.0170, -0.0160,  0.0612],\n",
       "          ...,\n",
       "          [-0.0185, -0.0429, -0.0778,  ...,  0.0221, -0.0339,  0.0211],\n",
       "          [-0.0369, -0.0228, -0.0589,  ..., -0.0346, -0.0254,  0.0585],\n",
       "          [-0.0128, -0.0192, -0.0552,  ...,  0.0255,  0.0379,  0.0548]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.key.lora_B.weight': tensor([[ 0.0195,  0.0090, -0.0192,  ..., -0.0263, -0.0147, -0.0115],\n",
       "          [ 0.0123, -0.0098, -0.0033,  ..., -0.0009,  0.0083,  0.0199],\n",
       "          [ 0.0263, -0.0202,  0.0056,  ...,  0.0249,  0.0211,  0.0191],\n",
       "          ...,\n",
       "          [ 0.0308, -0.0068, -0.0053,  ..., -0.0027,  0.0102, -0.0013],\n",
       "          [ 0.0030, -0.0193, -0.0002,  ...,  0.0164,  0.0249,  0.0185],\n",
       "          [-0.0292,  0.0063, -0.0039,  ..., -0.0016, -0.0076, -0.0054]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.value.lora_A.weight': tensor([[ 5.0136e-02, -2.9744e-02,  1.5235e-02,  ...,  2.8440e-02,\n",
       "           -3.4256e-02,  7.1275e-03],\n",
       "          [-1.8310e-02, -6.8224e-02, -5.4794e-02,  ..., -5.2184e-02,\n",
       "           -2.8081e-05,  9.0674e-03],\n",
       "          [-2.1656e-02,  1.4355e-02,  5.7137e-02,  ..., -4.1298e-02,\n",
       "            5.6155e-02,  3.0268e-02],\n",
       "          ...,\n",
       "          [ 2.1875e-02, -2.8341e-02,  4.5109e-02,  ..., -3.6560e-02,\n",
       "            1.1942e-02, -2.4748e-02],\n",
       "          [ 1.2260e-02, -1.7480e-02,  2.5903e-02,  ..., -3.6807e-02,\n",
       "           -8.1340e-03, -2.3467e-02],\n",
       "          [ 4.7514e-02, -7.6210e-03, -2.7888e-02,  ..., -1.8862e-02,\n",
       "           -2.7159e-02, -4.1776e-03]]),\n",
       "  'base_model.model.encoder.layer.3.attention.self.value.lora_B.weight': tensor([[ 0.0138, -0.0076, -0.0079,  ..., -0.0114, -0.0065,  0.0072],\n",
       "          [ 0.0149, -0.0175, -0.0204,  ..., -0.0152, -0.0169,  0.0156],\n",
       "          [ 0.0136,  0.0254, -0.0144,  ..., -0.0144, -0.0165,  0.0126],\n",
       "          ...,\n",
       "          [ 0.0043, -0.0034, -0.0066,  ...,  0.0063,  0.0049, -0.0042],\n",
       "          [-0.0015, -0.0124, -0.0100,  ...,  0.0029, -0.0118,  0.0084],\n",
       "          [-0.0105,  0.0060,  0.0030,  ...,  0.0021, -0.0033, -0.0026]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.query.lora_A.weight': tensor([[-0.0266,  0.0800,  0.0029,  ..., -0.0741,  0.0170, -0.0848],\n",
       "          [ 0.0688, -0.0021, -0.0269,  ...,  0.0270,  0.0383,  0.0802],\n",
       "          [ 0.0645,  0.0186,  0.0379,  ...,  0.0025, -0.0394,  0.0503],\n",
       "          ...,\n",
       "          [ 0.0063,  0.0240,  0.0020,  ...,  0.0328, -0.0016, -0.0186],\n",
       "          [ 0.0227, -0.0564, -0.0154,  ...,  0.0371,  0.0615,  0.0415],\n",
       "          [-0.0752,  0.0870,  0.0318,  ..., -0.0115, -0.0471, -0.0222]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.query.lora_B.weight': tensor([[-0.0043,  0.0030,  0.0056,  ...,  0.0037,  0.0043, -0.0060],\n",
       "          [ 0.0291, -0.0266, -0.0287,  ..., -0.0242, -0.0262,  0.0296],\n",
       "          [ 0.0001, -0.0021, -0.0012,  ..., -0.0066,  0.0002,  0.0047],\n",
       "          ...,\n",
       "          [ 0.0070, -0.0047, -0.0026,  ..., -0.0140, -0.0091,  0.0055],\n",
       "          [ 0.0052, -0.0058, -0.0044,  ..., -0.0064, -0.0044,  0.0112],\n",
       "          [ 0.0011,  0.0065,  0.0063,  ...,  0.0094,  0.0025, -0.0058]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.key.lora_A.weight': tensor([[-0.0557, -0.0380,  0.0514,  ..., -0.0192, -0.0284,  0.0182],\n",
       "          [-0.0289, -0.0133, -0.0142,  ...,  0.0199,  0.0393,  0.0555],\n",
       "          [-0.0584, -0.0009,  0.0500,  ...,  0.0178, -0.0467, -0.0530],\n",
       "          ...,\n",
       "          [-0.0357,  0.0157,  0.0324,  ..., -0.0047,  0.0309, -0.0419],\n",
       "          [ 0.0310,  0.0662, -0.0128,  ..., -0.0319,  0.0208, -0.0165],\n",
       "          [ 0.0052,  0.0199, -0.0522,  ...,  0.0234, -0.0282, -0.0233]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.key.lora_B.weight': tensor([[-0.0100, -0.0184,  0.0158,  ...,  0.0053,  0.0109, -0.0003],\n",
       "          [ 0.0104,  0.0067,  0.0118,  ...,  0.0036, -0.0003,  0.0044],\n",
       "          [ 0.0133,  0.0164, -0.0095,  ..., -0.0112, -0.0065,  0.0114],\n",
       "          ...,\n",
       "          [-0.0171, -0.0072, -0.0109,  ..., -0.0160,  0.0005,  0.0186],\n",
       "          [-0.0200, -0.0040, -0.0163,  ..., -0.0227, -0.0092,  0.0144],\n",
       "          [-0.0003,  0.0317, -0.0141,  ..., -0.0031, -0.0118, -0.0101]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.value.lora_A.weight': tensor([[ 0.0106, -0.0697,  0.0362,  ...,  0.0424,  0.0409, -0.0156],\n",
       "          [ 0.0615, -0.0652, -0.0052,  ...,  0.0351,  0.0603, -0.0118],\n",
       "          [-0.0320,  0.0233, -0.0088,  ..., -0.0078,  0.0546,  0.0628],\n",
       "          ...,\n",
       "          [-0.0127,  0.0038,  0.0549,  ...,  0.0734,  0.0343, -0.0508],\n",
       "          [-0.0237, -0.0278, -0.0538,  ..., -0.0482, -0.0033,  0.0825],\n",
       "          [-0.0209, -0.0498,  0.0304,  ..., -0.0349, -0.0632,  0.0086]]),\n",
       "  'base_model.model.encoder.layer.4.attention.self.value.lora_B.weight': tensor([[ 0.0065,  0.0152, -0.0099,  ...,  0.0196,  0.0170, -0.0212],\n",
       "          [-0.0122,  0.0106, -0.0119,  ...,  0.0095,  0.0062, -0.0053],\n",
       "          [ 0.0062,  0.0116,  0.0102,  ...,  0.0121,  0.0108, -0.0138],\n",
       "          ...,\n",
       "          [ 0.0266, -0.0216,  0.0285,  ..., -0.0308,  0.0036,  0.0253],\n",
       "          [ 0.0247,  0.0269,  0.0249,  ...,  0.0137,  0.0338, -0.0212],\n",
       "          [-0.0024, -0.0075, -0.0130,  ..., -0.0070, -0.0095,  0.0083]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.query.lora_A.weight': tensor([[-0.0239, -0.0355, -0.0188,  ..., -0.0456, -0.0471,  0.0336],\n",
       "          [-0.0164, -0.0204, -0.0658,  ..., -0.0054,  0.0276, -0.0104],\n",
       "          [-0.0584,  0.0034, -0.0473,  ..., -0.0679,  0.0003, -0.0331],\n",
       "          ...,\n",
       "          [ 0.0052, -0.0086, -0.0349,  ..., -0.0377,  0.0663, -0.0672],\n",
       "          [-0.0044, -0.0089,  0.0284,  ...,  0.0475,  0.0202, -0.0224],\n",
       "          [ 0.0047, -0.0232,  0.0386,  ..., -0.0449, -0.0461,  0.0599]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.query.lora_B.weight': tensor([[-0.0280, -0.0242, -0.0287,  ..., -0.0227, -0.0292,  0.0219],\n",
       "          [ 0.0098,  0.0044,  0.0121,  ...,  0.0095,  0.0098, -0.0090],\n",
       "          [-0.0200, -0.0103, -0.0244,  ..., -0.0184, -0.0166,  0.0140],\n",
       "          ...,\n",
       "          [-0.0156, -0.0235, -0.0132,  ..., -0.0197, -0.0176,  0.0208],\n",
       "          [-0.0154, -0.0143, -0.0109,  ..., -0.0122, -0.0128,  0.0137],\n",
       "          [ 0.0183,  0.0033,  0.0212,  ...,  0.0151,  0.0182, -0.0104]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.key.lora_A.weight': tensor([[ 0.0543, -0.0024, -0.0071,  ..., -0.0584, -0.0185,  0.0377],\n",
       "          [ 0.0044, -0.0417,  0.0332,  ..., -0.0097,  0.0754,  0.0511],\n",
       "          [-0.0335,  0.0338,  0.0311,  ...,  0.0046,  0.0691, -0.0313],\n",
       "          ...,\n",
       "          [-0.0248,  0.0355,  0.0304,  ...,  0.0201,  0.0601,  0.0160],\n",
       "          [-0.0514,  0.0659,  0.0246,  ...,  0.0409, -0.0434,  0.0405],\n",
       "          [-0.0296,  0.0292,  0.0584,  ...,  0.0412, -0.0131, -0.0411]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.key.lora_B.weight': tensor([[-0.0248,  0.0140, -0.0150,  ..., -0.0005,  0.0216,  0.0227],\n",
       "          [ 0.0278,  0.0038,  0.0229,  ...,  0.0064, -0.0222, -0.0101],\n",
       "          [ 0.0118, -0.0041,  0.0096,  ...,  0.0021, -0.0255, -0.0263],\n",
       "          ...,\n",
       "          [-0.0089,  0.0101,  0.0096,  ..., -0.0080,  0.0063, -0.0025],\n",
       "          [ 0.0130,  0.0022, -0.0087,  ..., -0.0106, -0.0151, -0.0093],\n",
       "          [ 0.0197, -0.0183,  0.0126,  ..., -0.0358, -0.0007,  0.0109]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.value.lora_A.weight': tensor([[-0.0282, -0.0286, -0.0399,  ..., -0.0189, -0.0621,  0.0537],\n",
       "          [ 0.0398, -0.0326,  0.0017,  ..., -0.0129, -0.0406,  0.0379],\n",
       "          [-0.0262, -0.0122,  0.0345,  ..., -0.0014, -0.0220,  0.0796],\n",
       "          ...,\n",
       "          [-0.0312,  0.0595, -0.0127,  ...,  0.0063, -0.0223, -0.0522],\n",
       "          [-0.0020, -0.0172,  0.0315,  ...,  0.0534,  0.0366, -0.0810],\n",
       "          [ 0.0251,  0.0384, -0.0328,  ..., -0.0008,  0.0371, -0.0287]]),\n",
       "  'base_model.model.encoder.layer.5.attention.self.value.lora_B.weight': tensor([[ 0.0334,  0.0047,  0.0384,  ..., -0.0119, -0.0210, -0.0090],\n",
       "          [-0.0251,  0.0166, -0.0292,  ..., -0.0192, -0.0085, -0.0201],\n",
       "          [-0.0059,  0.0073, -0.0049,  ..., -0.0125, -0.0080, -0.0096],\n",
       "          ...,\n",
       "          [-0.0293,  0.0191, -0.0245,  ..., -0.0089,  0.0012, -0.0166],\n",
       "          [ 0.0112,  0.0149,  0.0026,  ..., -0.0171, -0.0157, -0.0135],\n",
       "          [ 0.0133, -0.0315,  0.0139,  ...,  0.0350,  0.0185,  0.0337]])},\n",
       " 'ensemble_state_dict': OrderedDict([('0.weight',\n",
       "               tensor([[-0.0107, -0.0349,  0.0246, -0.0394, -0.0193,  0.0230, -0.0371, -0.0080,\n",
       "                         0.0025, -0.0587, -0.0412,  0.0810,  0.0341, -0.0110, -0.0186,  0.0735,\n",
       "                         0.0194, -0.0342, -0.0336,  0.0043,  0.0591, -0.0144, -0.0509,  0.0045,\n",
       "                        -0.0041, -0.0087,  0.0392, -0.0056, -0.0594, -0.0041, -0.0651, -0.0206,\n",
       "                        -0.0275,  0.0482,  0.0053, -0.0125, -0.0161,  0.0199,  0.0104, -0.0002,\n",
       "                        -0.0006, -0.0065,  0.0738,  0.0294,  0.0317,  0.0643,  0.0505, -0.0336,\n",
       "                         0.0482, -0.0602, -0.0374,  0.0575,  0.0676, -0.0181, -0.0352,  0.0168,\n",
       "                        -0.0773,  0.0639, -0.0311,  0.0198,  0.0179,  0.0123,  0.0045, -0.0438,\n",
       "                         0.0053, -0.0303, -0.0518, -0.0611, -0.0651, -0.0104, -0.0596,  0.0426,\n",
       "                         0.0102,  0.0601, -0.0070, -0.0111, -0.0231, -0.0090,  0.0122, -0.0053,\n",
       "                         0.0499,  0.0476,  0.0304, -0.0013, -0.0369,  0.0275, -0.0486,  0.0099,\n",
       "                         0.0010, -0.0196,  0.0483,  0.0300, -0.0140,  0.0092, -0.0660, -0.0121,\n",
       "                         0.0694, -0.0906, -0.0284, -0.0051, -0.0408,  0.0225,  0.0632, -0.0711,\n",
       "                         0.0700, -0.0029, -0.0341, -0.0660, -0.0575, -0.0645,  0.0522, -0.0185,\n",
       "                        -0.0114,  0.0158, -0.0226,  0.0685, -0.0126,  0.0054,  0.0741,  0.0180,\n",
       "                         0.0145, -0.0190, -0.0529, -0.0760,  0.0094,  0.0244, -0.0552, -0.0350,\n",
       "                        -0.0267, -0.0087, -0.0465, -0.0316, -0.0521, -0.0104,  0.0175,  0.0049,\n",
       "                         0.0386, -0.0344,  0.0514,  0.0700,  0.0162, -0.0644, -0.0634, -0.0538,\n",
       "                        -0.0593, -0.0423,  0.0116,  0.0556,  0.0396, -0.0828, -0.0195, -0.0186,\n",
       "                        -0.0106, -0.0122, -0.0379, -0.0209,  0.0508,  0.0148,  0.0112, -0.0287,\n",
       "                         0.0693,  0.0676, -0.0160,  0.0621,  0.0320, -0.0287,  0.0019,  0.0153,\n",
       "                        -0.0626, -0.0897, -0.0049, -0.0090, -0.0538,  0.0018, -0.0724, -0.0126,\n",
       "                        -0.0048,  0.0215,  0.0816,  0.0856,  0.0187,  0.0091, -0.0664,  0.0178,\n",
       "                        -0.0829, -0.0418, -0.0396,  0.0291, -0.0664, -0.0096,  0.0076, -0.0385,\n",
       "                         0.0190, -0.0119, -0.0307, -0.0106, -0.0530, -0.0515, -0.0602,  0.0644,\n",
       "                         0.0558, -0.0468,  0.0615,  0.0475, -0.0264, -0.0249, -0.0414, -0.0266,\n",
       "                        -0.0655,  0.0248,  0.0323,  0.0534, -0.0222,  0.0531, -0.0709,  0.0508,\n",
       "                         0.0713,  0.0331,  0.0519,  0.0057, -0.0007,  0.0544,  0.0405,  0.0030,\n",
       "                         0.0681, -0.0305,  0.0409, -0.0136,  0.0002, -0.0770, -0.0119, -0.0485,\n",
       "                        -0.0383, -0.0627,  0.0713, -0.0138, -0.0240,  0.0424,  0.0715,  0.0513,\n",
       "                        -0.0149, -0.0084,  0.0449,  0.0706, -0.0365, -0.0662, -0.0285, -0.0679,\n",
       "                        -0.0183,  0.0148, -0.0421, -0.0087, -0.0536,  0.0066,  0.0320,  0.0566,\n",
       "                         0.0198,  0.0246, -0.0607, -0.0268, -0.0117,  0.0178,  0.0005,  0.0702,\n",
       "                        -0.0824, -0.0531, -0.0319,  0.0805,  0.0134,  0.0604,  0.0496, -0.0182,\n",
       "                         0.0055,  0.0717,  0.0510, -0.0068, -0.0388,  0.0284,  0.0438,  0.0003,\n",
       "                        -0.0041, -0.0337,  0.0538, -0.0124, -0.0665, -0.0200, -0.0178, -0.0242,\n",
       "                        -0.0343, -0.0140,  0.0190,  0.0826, -0.0125,  0.0135, -0.0297,  0.0229,\n",
       "                         0.0463,  0.0055, -0.0494,  0.0486,  0.0078, -0.0380, -0.0486, -0.0087,\n",
       "                        -0.0174, -0.0773, -0.0092,  0.0708,  0.0242, -0.0036, -0.0535, -0.0799,\n",
       "                        -0.0425,  0.0356, -0.0142, -0.0328,  0.0021,  0.0686, -0.0517, -0.0055,\n",
       "                        -0.0184,  0.0021,  0.0131, -0.0286, -0.0284,  0.0439,  0.0273, -0.0138,\n",
       "                        -0.0484,  0.0070, -0.0514,  0.0696, -0.0145, -0.0180, -0.0153,  0.0172,\n",
       "                         0.0241,  0.0058, -0.0039,  0.0124,  0.0420,  0.0692, -0.0557,  0.0528,\n",
       "                        -0.0172,  0.0733,  0.0312,  0.0347,  0.0231,  0.0045,  0.0469,  0.0231]])),\n",
       "              ('0.bias', tensor([0.0269])),\n",
       "              ('1.weight',\n",
       "               tensor([[ 3.3258e-02, -6.0361e-02, -6.8026e-02, -7.5082e-02,  3.9741e-02,\n",
       "                         9.0278e-03, -2.4211e-02, -1.9232e-02, -4.7985e-02, -6.0254e-02,\n",
       "                         4.2143e-03,  3.7055e-02, -9.5075e-03, -2.3513e-02, -3.8017e-02,\n",
       "                        -1.6193e-02,  6.5050e-04, -8.8635e-03,  1.4179e-02, -5.6280e-03,\n",
       "                         5.1968e-02, -2.5035e-03, -7.0364e-02, -6.1577e-03,  4.8388e-02,\n",
       "                         5.0489e-02, -4.3897e-03,  1.3181e-02, -7.1544e-02, -1.5172e-03,\n",
       "                        -3.9081e-02, -1.7781e-02,  1.5622e-02,  5.8341e-02, -6.5228e-02,\n",
       "                         5.7779e-02, -1.5030e-02,  3.4026e-02,  4.9531e-02, -7.2869e-02,\n",
       "                        -5.8324e-02, -7.9781e-02,  3.0927e-02,  2.5095e-03,  5.6768e-02,\n",
       "                         1.4343e-02,  4.1177e-02, -4.0202e-02,  7.7671e-02, -2.3830e-02,\n",
       "                         2.3375e-02,  7.0141e-02,  6.6155e-02,  3.7693e-02,  1.0663e-02,\n",
       "                        -2.0691e-02, -3.6204e-02, -3.9722e-04, -6.5116e-02, -7.5177e-02,\n",
       "                        -1.4829e-02, -2.0346e-02, -6.6515e-03, -4.1670e-02,  1.8455e-02,\n",
       "                        -1.8592e-02, -6.1647e-02, -8.7617e-02, -4.3435e-03,  7.4225e-02,\n",
       "                        -4.0837e-02, -2.9272e-02, -8.7182e-03,  6.6944e-02,  7.8543e-03,\n",
       "                        -2.1061e-02,  1.1644e-02,  7.9401e-02,  5.6098e-02, -1.9056e-03,\n",
       "                         7.3177e-02,  4.6349e-02, -2.0667e-03, -2.8317e-02,  4.8002e-02,\n",
       "                         2.8003e-02,  1.6223e-02, -8.0156e-03,  1.9239e-02, -3.0780e-02,\n",
       "                         3.6508e-02, -2.7907e-02,  4.8250e-02,  6.3601e-02, -5.2040e-02,\n",
       "                        -7.0024e-02,  6.1796e-03, -8.8727e-02, -6.0987e-02, -2.0178e-03,\n",
       "                        -3.9085e-02,  3.5304e-02, -7.8417e-03, -6.9316e-02,  6.2970e-02,\n",
       "                         1.9466e-02,  3.3272e-03, -2.0087e-02, -5.4211e-02,  6.7878e-03,\n",
       "                         3.4311e-02, -2.1704e-02, -4.6283e-02,  2.1237e-02, -5.5275e-02,\n",
       "                         7.0709e-02, -5.6253e-02,  1.6569e-03,  8.9411e-02,  3.1872e-02,\n",
       "                         5.8319e-02, -1.1245e-02, -2.5745e-02,  8.7908e-03, -1.1736e-02,\n",
       "                         3.2754e-02, -6.5809e-02, -7.1208e-02,  1.5981e-02, -4.4147e-02,\n",
       "                        -4.3789e-02,  1.7215e-02,  1.8987e-02, -5.7693e-02,  7.3835e-02,\n",
       "                        -1.8064e-02,  6.9851e-02, -2.6556e-02,  5.0547e-02,  7.8993e-02,\n",
       "                        -3.9513e-02, -2.3213e-02, -3.0142e-02, -8.0371e-02, -5.1840e-02,\n",
       "                        -1.5330e-03,  1.3442e-02,  1.1929e-02,  1.7263e-02, -5.7167e-02,\n",
       "                        -7.7751e-02, -4.1877e-02, -9.3694e-03,  7.9965e-02, -4.2734e-02,\n",
       "                        -4.7486e-02,  2.3264e-02,  2.5126e-02,  6.5825e-02,  1.6351e-02,\n",
       "                        -5.3716e-03,  4.4281e-02,  2.0684e-02,  7.0299e-02,  2.3485e-02,\n",
       "                         3.2183e-02,  4.4735e-03, -3.8915e-02,  1.1716e-02, -9.6680e-02,\n",
       "                        -8.4769e-02,  7.0930e-03,  2.6171e-02, -2.4268e-03, -6.2338e-02,\n",
       "                         5.0519e-02,  4.1382e-02,  3.0133e-04,  2.9338e-02,  4.2615e-02,\n",
       "                         4.0319e-02,  4.2547e-02, -1.8625e-02, -2.0237e-02,  2.8538e-03,\n",
       "                        -4.5304e-02, -5.1931e-02, -5.7680e-02, -7.1609e-02, -6.4772e-02,\n",
       "                         2.3803e-02, -9.3784e-03,  2.7950e-02,  9.3252e-04,  5.3430e-02,\n",
       "                        -9.3199e-03, -7.7070e-02,  1.5637e-02,  6.8089e-03, -4.2996e-03,\n",
       "                         5.5902e-02, -6.8009e-02, -1.7909e-02, -8.9024e-03,  6.6384e-02,\n",
       "                        -8.5302e-02,  2.4830e-02, -3.9865e-02,  1.7028e-02, -6.1787e-02,\n",
       "                         5.4373e-02,  4.2294e-03,  4.2465e-02,  3.8376e-02, -6.9681e-02,\n",
       "                         6.9276e-02,  1.8288e-03,  6.3202e-02, -1.5840e-02,  5.6108e-02,\n",
       "                         1.4157e-02,  8.8076e-02,  3.3353e-02,  6.0493e-02,  3.8816e-02,\n",
       "                        -2.0737e-02, -2.8296e-03, -1.2126e-02,  3.5679e-02, -2.3744e-02,\n",
       "                        -5.9118e-03, -5.2518e-02,  4.0204e-02, -4.8970e-02,  6.5611e-03,\n",
       "                         5.3561e-02,  5.2423e-02, -3.9842e-02, -1.8075e-02, -3.8700e-02,\n",
       "                         2.3220e-02, -2.1537e-02,  1.8141e-02,  1.9308e-02, -3.3340e-02,\n",
       "                        -8.1262e-02, -5.0916e-02, -2.2427e-02,  7.3130e-02, -1.0330e-02,\n",
       "                        -4.5518e-02,  7.2702e-03,  2.1135e-02,  6.3244e-02, -5.9366e-02,\n",
       "                         1.2724e-02,  7.7396e-02, -3.4975e-02, -9.1555e-03,  3.0991e-02,\n",
       "                        -1.9562e-03,  8.1674e-03,  3.0649e-02,  1.8076e-02, -6.8719e-02,\n",
       "                        -5.6469e-03, -1.3514e-02,  7.9513e-02,  1.1741e-02,  3.5972e-02,\n",
       "                        -9.1006e-03,  1.5467e-03, -4.9649e-02,  8.3751e-03, -2.7362e-02,\n",
       "                        -2.1055e-02,  3.7730e-03,  1.5302e-02, -4.7227e-02,  4.8369e-03,\n",
       "                         3.2237e-02, -5.3918e-02, -4.1237e-03, -7.4845e-02, -5.8626e-02,\n",
       "                         2.8168e-02, -4.3906e-02,  6.9950e-02,  3.2979e-02,  3.8235e-02,\n",
       "                         3.5634e-02,  1.0532e-03,  2.7033e-02,  5.0666e-02,  1.6720e-02,\n",
       "                         3.6693e-02,  6.0840e-02,  1.0566e-02,  3.5149e-02, -6.8945e-03,\n",
       "                         1.4977e-02,  2.4288e-02, -6.2682e-02,  6.7325e-03, -4.6506e-02,\n",
       "                        -6.0048e-02, -1.7762e-02,  3.8975e-02,  5.4392e-02, -6.4170e-02,\n",
       "                        -3.4890e-02, -4.3579e-02, -2.1990e-02, -6.5075e-02, -3.4956e-02,\n",
       "                        -3.6142e-05,  2.2142e-03, -1.4789e-02, -6.5977e-02,  3.5039e-02,\n",
       "                        -6.5430e-02, -2.6684e-02,  6.8750e-02,  2.7942e-02,  9.7783e-03,\n",
       "                        -3.2089e-02, -3.0508e-02,  1.7075e-02, -3.7409e-02, -9.0837e-03,\n",
       "                         2.1361e-02, -2.1202e-02,  8.3872e-03,  1.0797e-02, -4.7755e-02,\n",
       "                         5.8396e-02, -3.7368e-03,  8.1926e-03,  2.8567e-02,  2.9720e-02,\n",
       "                         2.2490e-02,  1.9669e-02,  3.7749e-02, -1.5049e-02,  7.1699e-02,\n",
       "                         1.3338e-02,  3.9098e-02,  6.7926e-02,  4.4395e-02,  2.1120e-03,\n",
       "                         2.2511e-03, -3.2082e-02]])),\n",
       "              ('1.bias', tensor([-0.0381])),\n",
       "              ('2.weight',\n",
       "               tensor([[-2.0872e-02, -1.8199e-03,  6.9755e-03, -1.9551e-02,  3.3191e-03,\n",
       "                        -3.0348e-02,  4.0817e-02,  5.5559e-02, -7.4645e-02, -3.7669e-02,\n",
       "                        -2.2708e-02, -7.8461e-03, -3.7812e-02,  1.1281e-02, -1.6746e-02,\n",
       "                         2.8329e-02, -5.2001e-02,  4.1690e-02, -7.5361e-02, -1.2848e-02,\n",
       "                        -1.8390e-02, -6.3923e-03, -7.7555e-02,  5.0880e-02,  4.3166e-02,\n",
       "                         5.8285e-02, -2.1491e-02,  6.1122e-02, -8.0958e-02, -1.3733e-02,\n",
       "                        -5.4560e-02, -5.4162e-02,  1.1802e-02,  1.0671e-02, -5.6790e-02,\n",
       "                         7.8145e-02, -8.5454e-02,  7.5561e-03,  8.1047e-02, -4.6790e-02,\n",
       "                        -1.1189e-02, -1.1908e-02,  3.6983e-02,  2.8374e-02, -1.2844e-02,\n",
       "                         7.9551e-03,  2.6407e-02, -5.9837e-02, -1.2036e-02, -6.8700e-02,\n",
       "                         3.6290e-02,  5.6622e-02,  5.8811e-02,  4.0607e-02,  1.6720e-02,\n",
       "                        -3.9996e-02, -8.4575e-02,  1.3587e-02, -7.2117e-03, -3.4261e-02,\n",
       "                         9.5970e-03, -4.4295e-02,  4.4382e-02, -4.8309e-03,  5.0964e-02,\n",
       "                        -2.5654e-02, -8.3133e-02, -9.7192e-03, -8.8416e-02,  6.3884e-02,\n",
       "                        -1.4711e-02,  2.6354e-02,  1.3739e-04,  6.7612e-02, -7.3110e-02,\n",
       "                        -2.1535e-02, -1.4320e-02,  1.1013e-03,  3.9518e-02,  3.7181e-02,\n",
       "                        -1.1838e-02,  3.3395e-02, -8.4391e-03, -3.5780e-02,  1.4777e-02,\n",
       "                         1.7625e-02,  4.3321e-02, -1.6650e-02, -3.5741e-02, -4.0398e-02,\n",
       "                         2.1213e-02,  2.7380e-02, -1.2710e-04,  4.8834e-02, -2.9876e-02,\n",
       "                        -1.2403e-03,  8.2654e-02, -2.1426e-02, -4.0364e-02, -4.2389e-02,\n",
       "                        -1.1502e-02,  6.3385e-02,  2.3610e-02, -7.8360e-02,  6.1425e-02,\n",
       "                        -4.9162e-02, -3.4522e-02, -6.8797e-02, -1.2280e-02,  1.2345e-02,\n",
       "                         3.9578e-02,  1.8652e-02, -2.5648e-02,  2.0018e-02, -2.6814e-02,\n",
       "                         7.7487e-02, -9.0709e-03, -1.2573e-03,  7.3147e-03,  8.5994e-03,\n",
       "                         9.4473e-02, -6.2257e-03,  3.8605e-02, -6.4505e-02, -9.2120e-06,\n",
       "                         4.8629e-02, -2.4508e-02, -1.9285e-03, -5.7808e-02,  1.5300e-02,\n",
       "                        -7.2300e-02,  2.5777e-02, -4.9224e-02, -4.2722e-03, -4.4231e-03,\n",
       "                        -1.1561e-03,  5.0970e-02, -2.9491e-02, -7.5869e-03, -1.1290e-02,\n",
       "                        -7.2752e-03,  2.3516e-02,  1.3311e-02, -7.5594e-02, -1.3768e-02,\n",
       "                         2.7868e-02, -2.4691e-02,  7.2850e-02, -2.0445e-02,  2.0776e-03,\n",
       "                        -2.5963e-02,  4.2419e-03, -4.4502e-02,  9.8219e-03,  1.1889e-02,\n",
       "                        -4.5466e-02,  3.2094e-02, -4.4882e-04, -2.2201e-02,  6.6316e-02,\n",
       "                         2.2498e-02,  5.0454e-02, -3.8578e-02,  7.6965e-02, -4.0063e-02,\n",
       "                         6.8572e-03,  5.4637e-03,  3.5632e-02, -4.8366e-03, -1.7419e-02,\n",
       "                        -1.5523e-02,  6.1875e-03,  3.9852e-02, -3.0820e-02, -7.3192e-02,\n",
       "                        -2.5616e-02,  6.6789e-02,  4.9426e-02,  4.8541e-02,  1.6534e-02,\n",
       "                        -2.4969e-02,  4.0825e-02, -7.8378e-02, -5.5281e-02, -8.3365e-02,\n",
       "                         2.2852e-02,  2.4471e-02, -3.0895e-02, -6.1417e-03, -5.9812e-02,\n",
       "                        -1.0389e-02, -4.6495e-02,  5.4969e-02,  3.4218e-02,  6.2890e-02,\n",
       "                         4.3868e-02, -1.8382e-03, -4.0122e-02, -2.3255e-02,  5.2923e-02,\n",
       "                        -7.4058e-04, -8.6732e-02, -4.0215e-02,  5.0653e-02,  1.8534e-02,\n",
       "                        -2.6023e-02, -4.1368e-02, -7.0863e-02,  7.9870e-03,  1.5790e-02,\n",
       "                         4.9638e-02,  5.5602e-02,  5.7658e-02,  1.3230e-03, -3.3447e-02,\n",
       "                         2.8277e-02,  8.2348e-02,  6.7564e-02,  5.0894e-02, -2.9455e-02,\n",
       "                         5.7218e-02, -1.5042e-02,  6.8596e-03,  4.3258e-03,  7.3605e-02,\n",
       "                        -7.6903e-03,  1.0316e-02, -1.7931e-02, -4.0974e-02, -7.2012e-02,\n",
       "                         4.3110e-02, -8.2634e-02, -2.6444e-03, -5.6651e-02,  6.3653e-02,\n",
       "                        -1.6609e-02,  5.3479e-02,  2.0723e-02, -2.0809e-02, -3.7591e-02,\n",
       "                         2.0959e-02, -5.6929e-02,  4.2018e-03,  3.0337e-02, -2.1550e-02,\n",
       "                        -8.3799e-02, -3.8065e-02, -6.4932e-02,  3.5772e-02, -6.2144e-02,\n",
       "                        -4.8488e-02,  2.5852e-02, -5.5652e-02,  7.7504e-02, -6.4610e-02,\n",
       "                         5.9142e-02,  5.9987e-02, -1.5310e-03, -8.5014e-02, -2.4248e-02,\n",
       "                        -7.4208e-02, -4.0268e-02, -3.7015e-02,  7.5670e-02, -3.3656e-02,\n",
       "                        -6.9848e-02,  1.2234e-02,  1.7526e-02, -4.0304e-02,  3.7780e-02,\n",
       "                         6.6597e-04, -8.5760e-02, -4.8242e-04,  1.0471e-02,  4.1480e-02,\n",
       "                         4.7030e-03, -5.6625e-02,  5.1590e-02, -4.1671e-03,  6.6572e-02,\n",
       "                         1.6295e-02,  1.0470e-03,  3.8947e-02, -1.3151e-02, -1.8488e-02,\n",
       "                         1.8108e-02,  7.2106e-03, -3.0886e-03,  5.1554e-02,  2.7158e-02,\n",
       "                         2.9008e-02,  7.5163e-02,  2.3148e-02,  3.1725e-02, -1.6309e-02,\n",
       "                        -1.5230e-02,  1.3692e-02,  3.6243e-02,  2.7177e-02, -9.9958e-03,\n",
       "                         6.0910e-02, -4.8126e-02, -5.0041e-02, -7.8590e-03, -1.2988e-02,\n",
       "                        -5.2001e-02,  5.1291e-02,  7.5168e-02,  6.8544e-02, -1.2666e-03,\n",
       "                        -4.1150e-02,  1.9790e-02,  1.5374e-02, -1.5841e-02, -3.6490e-02,\n",
       "                        -5.8801e-03,  5.8307e-02,  4.8722e-02, -6.5076e-02, -1.6753e-04,\n",
       "                        -2.7851e-02,  2.2217e-02,  5.8660e-02,  3.4354e-02,  7.0494e-02,\n",
       "                         1.4598e-02,  6.9120e-02,  4.9576e-02, -1.4594e-04,  1.0178e-02,\n",
       "                        -3.6819e-02,  7.2222e-02,  3.0897e-02, -2.1715e-02, -5.4957e-02,\n",
       "                        -7.7364e-03,  7.6009e-03,  1.0142e-02, -1.0814e-02,  4.7337e-03,\n",
       "                         3.8246e-02, -2.1865e-02,  1.9797e-03, -4.4423e-02,  6.6780e-02,\n",
       "                         2.8589e-02,  6.4834e-03,  6.5980e-02,  7.2945e-02,  1.2089e-02,\n",
       "                         6.7597e-02, -1.6928e-02]])),\n",
       "              ('2.bias', tensor([-0.0104]))]),\n",
       " 'pooler_state_dict': OrderedDict([('dense.weight',\n",
       "               tensor([[-0.0158,  0.0002, -0.0083,  ...,  0.0033,  0.0041, -0.0128],\n",
       "                       [-0.0266, -0.0139, -0.0267,  ..., -0.0024,  0.0195, -0.0040],\n",
       "                       [-0.0340,  0.0138, -0.0217,  ...,  0.0224, -0.0120,  0.0147],\n",
       "                       ...,\n",
       "                       [-0.0555, -0.0383, -0.0293,  ...,  0.0034, -0.0142, -0.0126],\n",
       "                       [-0.0006, -0.0054,  0.0036,  ..., -0.0252,  0.0113, -0.0050],\n",
       "                       [ 0.0007, -0.0032,  0.0169,  ...,  0.0418, -0.0013, -0.0201]])),\n",
       "              ('dense.bias',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0.]))]),\n",
       " 'hparams': {'label': 'encoded_expression',\n",
       "  'num_heads': 3,\n",
       "  'model_name': 'facebook/esm2_t6_8M_UR50D',\n",
       "  'lr': 0.0005,\n",
       "  'peft_r': 8,\n",
       "  'peft_alpha': 16,\n",
       "  'max_length': 512,\n",
       "  'xvar': 'sequence',\n",
       "  'dropout': 0.0,\n",
       "  'explore_weight': 0.2,\n",
       "  'loss_type': 'bt'},\n",
       " 'model_name': 'facebook/esm2_t6_8M_UR50D',\n",
       " 'feature_projection_state': OrderedDict([('0.weight',\n",
       "               tensor([[ 0.3218, -0.4973,  0.0863,  0.1991],\n",
       "                       [ 0.3510, -0.1058,  0.0066, -0.2764],\n",
       "                       [ 0.4546,  0.1220,  0.2660, -0.1924],\n",
       "                       [-0.3205, -0.2628, -0.0303,  0.4945],\n",
       "                       [-0.1039,  0.0715, -0.4060,  0.1121],\n",
       "                       [-0.3798,  0.4668, -0.1885, -0.0154],\n",
       "                       [-0.3531, -0.2231, -0.0889,  0.0098],\n",
       "                       [-0.2208,  0.2297,  0.4154,  0.3216],\n",
       "                       [ 0.3949,  0.3785,  0.0487, -0.1847],\n",
       "                       [-0.3440,  0.2272, -0.0778, -0.1711],\n",
       "                       [ 0.3545, -0.1071, -0.2177,  0.1959],\n",
       "                       [-0.2022,  0.2895,  0.3146,  0.0264],\n",
       "                       [-0.4702, -0.1890, -0.2736,  0.4231],\n",
       "                       [ 0.1878,  0.4236, -0.0550, -0.4815],\n",
       "                       [ 0.2058,  0.3823, -0.3202, -0.4568],\n",
       "                       [-0.0398, -0.2097,  0.4966,  0.0951],\n",
       "                       [-0.0856,  0.0597, -0.2922,  0.2055],\n",
       "                       [-0.0543, -0.0246,  0.4128,  0.3736],\n",
       "                       [ 0.3472, -0.0910, -0.1754,  0.4647],\n",
       "                       [ 0.0900,  0.1464, -0.0559,  0.2755],\n",
       "                       [-0.4475,  0.4643, -0.1978, -0.4185],\n",
       "                       [ 0.1302,  0.0351,  0.0845, -0.2562],\n",
       "                       [ 0.3170,  0.0685, -0.3302, -0.3248],\n",
       "                       [ 0.0728, -0.4140, -0.0787, -0.3365],\n",
       "                       [-0.2976,  0.3963,  0.0865, -0.4290],\n",
       "                       [-0.1968, -0.2108, -0.2108,  0.0857],\n",
       "                       [ 0.2627,  0.2018,  0.2059,  0.0188],\n",
       "                       [-0.1364,  0.4421,  0.3938, -0.4206],\n",
       "                       [-0.0008, -0.4346,  0.1711, -0.4298],\n",
       "                       [ 0.2432,  0.0072, -0.2439, -0.2007],\n",
       "                       [-0.0360,  0.2199,  0.1077,  0.0271],\n",
       "                       [ 0.3068, -0.4507, -0.4197, -0.4906]])),\n",
       "              ('0.bias',\n",
       "               tensor([-0.2764, -0.0122,  0.3127, -0.4679,  0.2214,  0.0939,  0.1435, -0.2442,\n",
       "                       -0.4749, -0.0733, -0.2913,  0.1974,  0.3363, -0.2577, -0.3912,  0.1440,\n",
       "                        0.0835, -0.4920, -0.1932, -0.1966, -0.0240,  0.3918, -0.0260,  0.2867,\n",
       "                       -0.3822, -0.2551, -0.2712,  0.1930, -0.3645, -0.3849,  0.0882,  0.4680])),\n",
       "              ('2.weight',\n",
       "               tensor([1.0252, 0.9906, 1.0227, 0.9952, 1.0127, 0.9950, 1.0235, 1.0139, 1.0188,\n",
       "                       0.9857, 1.0247, 1.0220, 0.9905, 1.0045, 1.0206, 1.0229, 0.9945, 0.9912,\n",
       "                       0.9991, 0.9945, 1.0221, 1.0262, 0.9961, 0.9970, 1.0211, 1.0221, 1.0015,\n",
       "                       1.0211, 1.0213, 0.9823, 1.0219, 0.9848])),\n",
       "              ('2.bias',\n",
       "               tensor([-8.9521e-05, -8.4681e-05, -2.1594e-05, -1.0432e-05, -5.6931e-05,\n",
       "                       -5.6992e-05, -1.8515e-04, -5.8702e-05, -2.0487e-04, -8.2453e-05,\n",
       "                        7.5983e-05, -1.2827e-04, -6.1381e-05,  6.8205e-05, -6.0839e-06,\n",
       "                        1.2814e-04, -1.3034e-04,  7.5520e-05,  6.5560e-06,  1.0602e-04,\n",
       "                       -4.6490e-05, -1.5559e-05,  9.1015e-05, -5.9966e-05, -2.6970e-05,\n",
       "                       -5.6247e-05,  1.6237e-04, -1.0034e-04, -4.1331e-04, -1.9387e-05,\n",
       "                       -1.3493e-04, -2.6323e-05]))])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model('expression_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/src/egfr_binder_rd2/bt.py:546: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  def load_model(cls, load_path: str):\n",
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: expression_model.pt\n",
      "Loaded adapter state dict keys: ['base_model.model.encoder.layer.0.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.0.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.0.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.0.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.0.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.0.attention.self.value.lora_B.weight', 'base_model.model.encoder.layer.1.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.1.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.1.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.1.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.1.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.1.attention.self.value.lora_B.weight', 'base_model.model.encoder.layer.2.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.2.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.2.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.2.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.2.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.2.attention.self.value.lora_B.weight', 'base_model.model.encoder.layer.3.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.3.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.3.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.3.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.3.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.3.attention.self.value.lora_B.weight', 'base_model.model.encoder.layer.4.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.4.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.4.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.4.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.4.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.4.attention.self.value.lora_B.weight', 'base_model.model.encoder.layer.5.attention.self.query.lora_A.weight', 'base_model.model.encoder.layer.5.attention.self.query.lora_B.weight', 'base_model.model.encoder.layer.5.attention.self.key.lora_A.weight', 'base_model.model.encoder.layer.5.attention.self.key.lora_B.weight', 'base_model.model.encoder.layer.5.attention.self.value.lora_A.weight', 'base_model.model.encoder.layer.5.attention.self.value.lora_B.weight']\n",
      "Loaded ensemble state dict keys: ['0.regression_head.0.weight', '0.regression_head.0.bias', '0.regression_head.3.weight', '0.regression_head.3.bias', '0.regression_head.4.weight', '0.regression_head.4.bias', '0.regression_head.7.weight', '0.regression_head.7.bias', '0.regression_head.8.weight', '0.regression_head.8.bias', '1.regression_head.0.weight', '1.regression_head.0.bias', '1.regression_head.3.weight', '1.regression_head.3.bias', '1.regression_head.4.weight', '1.regression_head.4.bias', '1.regression_head.7.weight', '1.regression_head.7.bias', '1.regression_head.8.weight', '1.regression_head.8.bias', '2.regression_head.0.weight', '2.regression_head.0.bias', '2.regression_head.3.weight', '2.regression_head.3.bias', '2.regression_head.4.weight', '2.regression_head.4.bias', '2.regression_head.7.weight', '2.regression_head.7.bias', '2.regression_head.8.weight', '2.regression_head.8.bias', '3.regression_head.0.weight', '3.regression_head.0.bias', '3.regression_head.3.weight', '3.regression_head.3.bias', '3.regression_head.4.weight', '3.regression_head.4.bias', '3.regression_head.7.weight', '3.regression_head.7.bias', '3.regression_head.8.weight', '3.regression_head.8.bias', '4.regression_head.0.weight', '4.regression_head.0.bias', '4.regression_head.3.weight', '4.regression_head.3.bias', '4.regression_head.4.weight', '4.regression_head.4.bias', '4.regression_head.7.weight', '4.regression_head.7.bias', '4.regression_head.8.weight', '4.regression_head.8.bias', '5.regression_head.0.weight', '5.regression_head.0.bias', '5.regression_head.3.weight', '5.regression_head.3.bias', '5.regression_head.4.weight', '5.regression_head.4.bias', '5.regression_head.7.weight', '5.regression_head.7.bias', '5.regression_head.8.weight', '5.regression_head.8.bias', '6.regression_head.0.weight', '6.regression_head.0.bias', '6.regression_head.3.weight', '6.regression_head.3.bias', '6.regression_head.4.weight', '6.regression_head.4.bias', '6.regression_head.7.weight', '6.regression_head.7.bias', '6.regression_head.8.weight', '6.regression_head.8.bias', '7.regression_head.0.weight', '7.regression_head.0.bias', '7.regression_head.3.weight', '7.regression_head.3.bias', '7.regression_head.4.weight', '7.regression_head.4.bias', '7.regression_head.7.weight', '7.regression_head.7.bias', '7.regression_head.8.weight', '7.regression_head.8.bias', '8.regression_head.0.weight', '8.regression_head.0.bias', '8.regression_head.3.weight', '8.regression_head.3.bias', '8.regression_head.4.weight', '8.regression_head.4.bias', '8.regression_head.7.weight', '8.regression_head.7.bias', '8.regression_head.8.weight', '8.regression_head.8.bias', '9.regression_head.0.weight', '9.regression_head.0.bias', '9.regression_head.3.weight', '9.regression_head.3.bias', '9.regression_head.4.weight', '9.regression_head.4.bias', '9.regression_head.7.weight', '9.regression_head.7.bias', '9.regression_head.8.weight', '9.regression_head.8.bias']\n",
      "Loaded pooler state dict keys: ['dense.weight', 'dense.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naka/code/egfr_binder_rd2/.venv/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/naka/code/egfr_binder_rd2/src/egfr_binder_rd2/bt.py:666: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = super().load_model(load_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PartialEnsembleModuleWithFeatures(\n",
       "  (esm_model): PeftModelForFeatureExtraction(\n",
       "    (base_model): LoraModel(\n",
       "      (model): EsmModel(\n",
       "        (embeddings): EsmEmbeddings(\n",
       "          (word_embeddings): Embedding(33, 320, padding_idx=1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (position_embeddings): Embedding(1026, 320, padding_idx=1)\n",
       "        )\n",
       "        (encoder): EsmEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x EsmLayer(\n",
       "              (attention): EsmAttention(\n",
       "                (self): EsmSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=320, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=320, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=320, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=320, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=320, out_features=320, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Identity()\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=320, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=320, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (rotary_embeddings): RotaryEmbedding()\n",
       "                )\n",
       "                (output): EsmSelfOutput(\n",
       "                  (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (intermediate): EsmIntermediate(\n",
       "                (dense): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              )\n",
       "              (output): EsmOutput(\n",
       "                (dense): Linear(in_features=1280, out_features=320, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm_after): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (pooler): EsmPooler(\n",
       "          (dense): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "        (contact_head): EsmContactPredictionHead(\n",
       "          (regression): Linear(in_features=120, out_features=1, bias=True)\n",
       "          (activation): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ensemble_heads): ModuleList(\n",
       "    (0-9): 10 x PartialEnsembleHead(\n",
       "      (regression_head): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=400, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.15, inplace=False)\n",
       "        (3): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Linear(in_features=400, out_features=200, bias=True)\n",
       "        (5): ReLU()\n",
       "        (6): Dropout(p=0.15, inplace=False)\n",
       "        (7): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Linear(in_features=200, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (train_metrics): MetricCollection(\n",
       "    (train_mae): MeanAbsoluteError()\n",
       "    (train_spearman): SpearmanCorrCoef()\n",
       "  )\n",
       "  (val_mae): MeanAbsoluteError()\n",
       "  (val_spearman): SpearmanCorrCoef()\n",
       "  (bt_loss): BradleyTerryLoss()\n",
       "  (mse_loss): MSELoss()\n",
       "  (feature_projection): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=80, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartialEnsembleModuleWithFeatures.load_model('expression_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EsmTokenizer(name_or_path='facebook/esm2_t6_8M_UR50D', vocab_size=33, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<cls>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.encode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
